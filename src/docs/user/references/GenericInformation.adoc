
In addition to variables, another key/value structure can be accessed inside a script: *_Generic Information_*.

Generic information semantics differ from <<_job_variables>> semantics in the following way:

* Generic information can be accessed inside a script, but cannot be modified.
* Generic information can be defined at *job-level* or at *task-level*. If the same generic information is defined both at job-level and at task-level, the latter value takes precedence inside the task scope.
* Generic information cannot be used directly inside the workflow with the syntax ${} (See  <<_job_variables>>).
* Generic information are used in general internally by the scheduler, for example to provide information to the scheduling loop on how to handle the task. An example of such generic information is the _START_AT_ info used inside <<_cron_tasks>>.
* Generic information can use in their definition job/task variables patterns, pattern replacements can be done at execution time when using task generic information.
* Generic information need in most cases to be defined manually by the workflow designer, but some generic information such as _PARENT_JOB_ID_ are defined automatically by ProActive.

Example of a generic information definition:

For example:
[source, xml]
----
<task ... >
    <genericInformation>
        <info name="ginfo" value="${test}"/>
    </genericInformation>
    ...
</task>
----

Some generic information can also be configured globally on the ProActive server. These *global generic information* will then apply to all submitted workflows or to certain categories of workflows (e.g. workflows with a given name). Global generic information are *job-level* only.

See link:../admin/ProActiveAdminGuide.html#_configure_global_variables_and_generic_information[Configure Global Variables and Generic Information] section to understand how global generic information can be configured on the ProActive server.

The following table describes all available generic information:

.Generic Information
|===
|*Name* |*Description* |*Scope* | *Mode* | *Example*
5+^|*Resource Manager*
|<<_node_access_token,NODE_ACCESS_TOKEN>>
|execute task(s) on node(s) with token-based usage restriction
|job-level, task-level
|Manual
|my_token
|<<_node_source_generic_info,NODE_SOURCE>>
|execute task(s) on node(s) belonging to the given node source. Provision nodes if needed similarly to <<_native_scheduler,NS>> or <<_nodesourcename,NODESOURCENAME>>.
|job-level, task-level
|Manual
|MyNodeSource
|<<_native_scheduler,NS>>
|run the task on a <<../admin/ProActiveAdminGuide.html#_deploy_via_other_schedulers,Native Scheduler Node Source>>. Provision a new node to run the task on the associated cluster. Value is the Node Source name. *Deprecated*, consider using <<_node_source_generic_info>> instead.
|job-level,task-level
|Manual
|SLURM
|<<_native_scheduler,NS_BATCH>>
|extra parameters given to the native scheduler command
|job-level,task-level
|Manual
|-q queue1 -lnodes=2:ppn=2
|<<_native_scheduler,NS_PRE>>
|command run before the ProActive Node is started inside the Native Scheduler infrastructure
|job-level,task-level
|Manual
|module load mpi/gcc/openmpi-1.6.4
|<<_nodesourcename,NODESOURCENAME>>
|run the task on a Node Source controlled by a <<../admin/ProActiveAdminGuide.html#_dynamic_policy,Dynamic Policy>> (generally cloud node sources). Provision a new node to run the task on the associated node source. Value is the Node Source name. *Deprecated*, consider using <<_node_source_generic_info>> instead.
|job-level,task-level
|Manual
|Azure
|<<_resource_tags,RESOURCE_TAGS>>
|add tags to cloud instances acquired by a Node Source controlled by a <<../admin/ProActiveAdminGuide.html#_dynamic_policy,Dynamic Policy>> (only available when the associated infrastructure is an <<../admin/ProActiveAdminGuide.html#_azure_scale_set_infrastructure,Azure Scale Set Infrastructure>>). Definition must be a json key/value structure which contain tag names and values.
|job-level,task-level
|Manual
|{
"tagName1" :  "tagValue1",
"tagName2" :  "tagValue2"
}
5+^|*Scheduling*
|<<_start_at,START_AT>>
|delay a job or task execution at a specified date/time
|job-level, task-level
|Manual
|2020-06-20T18:00:00+02:00
|<<_earliest_deadline_first_policy,JOB_DDL>>
|job deadline used in <<../admin/ProActiveAdminGuide.html#_earliest_deadline_first_edf_policy,Earliest Deadline First Scheduling Policy>>
|job-level
|Manual
|+5:30:00
|<<_earliest_deadline_first_policy,JOB_EXEC_TIME>>
|job expected execution time used in <<../admin/ProActiveAdminGuide.html#_earliest_deadline_first_edf_policy,Earliest Deadline First Scheduling Policy>>
|job-level
|Manual
|1:00:00
|<<_required_licenses,REQUIRED_LICENSES>>
|comma-separated list of licenses used by this job or this task. See <<../admin/ProActiveAdminGuide.html#_license_policy,License Policy>>
|job-level, task-level
|Manual
|software_A,software_B
|<<_max_nodes_usage,MAX_NODES_USAGE>>
|number of Nodes that this job and all its sub-jobs are allowed to use in parallel. See <<../admin/ProActiveAdminGuide.html#_node_usage_policy,Node Usage Policy>>
|job-level
|Manual
|10
|<<_walltime,WALLTIME>>
|maximum execution time of a task
|job-level, task-level
|Manual
|10:00
5+^|*User Interface*
|<<_parent_job_id,PARENT_JOB_ID>>
|contains the id of the parent job (if the current job has been submitted from another workflow)
|job-level
|Automatic
|24
|<<_documentation,Documentation>>
|Add a documentation link to the workflow
|job-level
|Manual
|\http://my-server/my-doc.html
|<<_documentation,task.documentation>>
|Add a documentation link to the task
|task-level
|Manual
|\http://my-server/my-doc.html
|<<_icon_management,workflow.icon>>
|Add an icon to the workflow
|job-level
|Manual
|\http://my-server/my-icon.png
|<<_icon_management,task.icon>>
|Add an icon to the task
|task-level
|Manual
|\http://my-server/my-icon.png
|<<_job_planner,calendar.name>>
|generic information automatically added by the Job Planner. It contains the name of the calendar based on which the job is planned.
|job-level
|Automatic
|every_10_minutes
|<<_job_planner,next.execution>>
|generic information automatically added by the Job Planner. It contains the next execution date of the job.
|job-level
|Automatic
|2022-04-26 12:50:00 CEST
|<<_submission_mode,submission.mode>>
|contains the origin from which the job was submitted.
|job-level
|Automatic
|job-planner
5+^|*Notification*
|<<_email,EMAIL>>
|send email to recipient(s) based on job state events
|job-level
|Manual
|user@example.com
|<<_email,NOTIFICATION_EVENTS>>
|a list of job events associated with email notifications
|job-level
|Manual
|JOB_PENDING_TO_RUNNING, JOB_RUNNING_TO_FINISHED
5+^|*Housekeeping*
|<<_remove_delay,REMOVE_DELAY>>
|once the job is terminated, this setting controls the delay after which it will be removed from the scheduler database
|job-level
|Manual
|3d 12h
|<<_remove_delay,REMOVE_DELAY_ON_ERROR>>
|once the job is terminated with errors, this setting controls the delay after which it will be removed from the scheduler database. This generic information should be set in addition to REMOVE_DELAY when there is a need to keep the job longer in the scheduler database in case of error.
|job-level
|Manual
|3d 12h
5+^|*Task Control*
|<<_disable_ptk,DISABLE_PTK>>
|skip sub-process cleaning after the task is terminated
|task-level
|Manual
|true
|<<_pre_script_as_file,PRE_SCRIPT_AS_FILE>>
|skip pre-script execution and store its content as a file
|task-level
|Manual
|my_prescript.py
5+^|*Result Format*
|<<_result_metadata,content.type>>
|Assign a MIME content type to a byte array task result
|task-level
|Manual
|image/png
|<<_result_metadata,file.name>>
|Assign a file name to a byte array task result
|task-level
|Manual
|image_balloon.png
|<<_result_metadata,file.extension>>
|Assign a file extension to a byte array task result
|task-level
|Manual
|.png
5+^|*Run As User*
|link:../user/ProActiveUserGuide.html#_run_as_me_generic_info[RUNAS_METHOD]
|Allows overriding the impersonation method used when executing the task. Can be `pwd`, `key` or `none`.
|job-level, task-level
|Manual
|`pwd`
|link:../user/ProActiveUserGuide.html#_run_as_me_generic_info[RUNAS_USER]
|Allows overriding the login name used during the impersonation. This allows to run a task under a different user as the user who submitted the workflow.
|job-level, task-level
|Manual
|bob
|link:../user/ProActiveUserGuide.html#_run_as_me_generic_info[RUNAS_DOMAIN]
|Allows defining or overriding a user domain that will be attached to the impersonated user. User domains are only used on Windows operating systems.
|job-level, task-level
|Manual
|MyOrganisation
|link:../user/ProActiveUserGuide.html#_run_as_me_generic_info[RUNAS_PWD]
|Allows overriding the password attached to the impersonated user. This can be used only when the impersonation method is set to `pwd`.
|job-level, task-level
|Manual
|MyPassword
|link:../user/ProActiveUserGuide.html#_run_as_me_generic_info[RUNAS_PWD_CRED]
|Similar to RUNAS_PWD but the password will be defined inside link:../user/ProActiveUserGuide.adoc#_third_party_credentials[Third-Party Credential] instead of inlined in the workflow. This method of defining the password should be preferred to RUNAS_PWD for security reasons. The value of RUNAS_PWD_CRED must be the third-party credential name containing the user password.
|job-level, task-level
|Manual
|MyPasswordCredName
|link:../user/ProActiveUserGuide.html#_run_as_me_generic_info[RUNAS_SSH_KEY_CRED]
|Allows overriding the SSH private key attached to the impersonated user. This can be used only when the impersonation method is set to `key`. The private key will be defined inside link:../user/ProActiveUserGuide.adoc#_third_party_credentials[Third-Party Credential] instead of inlined in the workflow. The value of RUNAS_SSH_KEY_CRED must be the third-party credential name containing the SSH key.
|job-level, task-level
|Manual
|MySSHKeyCredName
5+^|*CPython engine*
|<<_python_command,PYTHON_COMMAND>>
|Python command to use in <<../user/ProActiveUserGuide.adoc#_python,CPython script engine>>.
|job-level, task-level
|Manual
|python3
5+^|*Docker Compose engine*
|<<_docker_compose_options,docker-compose-options>>
|general parameters given to the docker-compose command in <<../user/ProActiveUserGuide.adoc#_docker_compose,Docker Compose script engine>>.
|job-level, task-level
|Manual
|--verbose
|<<_docker_compose_options,docker-compose-up-options>>
|general parameters given to the docker-compose up command in <<../user/ProActiveUserGuide.adoc#_docker_compose,Docker Compose script engine>>.
|job-level, task-level
|Manual
|--exit-code-from helloworld
|<<_docker_compose_options,docker-compose-options-split-regex>>
|declare a string to be used as options separator in <<../user/ProActiveUserGuide.adoc#_docker_compose,Docker Compose script engine>>.
|job-level, task-level
|Manual
|!SPLIT!
5+^|*Dockerfile engine*
|<<_dockerfile_options,docker-actions>>
|actions to perform in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|task-level
|Manual
|build,run
|<<_dockerfile_options,docker-image-tag>>
|tag identifying the docker image in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|task-level
|Manual
|my-image
|<<_dockerfile_options,docker-container-tag>>
|tag identifying the docker container in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|task-level
|Manual
|my-container
|<<_dockerfile_options,docker-build-options>>
|options given to the `docker build` command in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|--no-cache
|<<_dockerfile_options,docker-run-options>>
|options given to the `docker run` command in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|--detach
|<<_dockerfile_options,docker-exec-command>>
|command given to `docker exec`, if used in *docker-actions*. See <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|/bin/sh -c echo 'hello'
|<<_dockerfile_options,docker-exec-options>>
|options given to the `docker exec` command in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|-t -w /my/work/dir
|<<_dockerfile_options,docker-stop-options>>
|options given to the `docker stop` command in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|--time 20
|<<_dockerfile_options,docker-rm-options>>
|options given to the `docker rm` command in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|--volumes
|<<_dockerfile_options,docker-rmi-options>>
|options given to the `docker rmi` command in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|--force
|<<_dockerfile_options,docker-file-options-split-regex>>
|declare a string to be used as options separator in <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script engine>>.
|job-level, task-level
|Manual
|!SPLIT!
|===

==== START_AT

The `START_AT` Generic Information can be used to delay a job or task execution at a specified date/time.
Its value should be https://en.wikipedia.org/wiki/ISO_8601[ISO 8601^] compliant. See <<_cron_tasks>> for more details.

Examples:

 * `START_AT = "2020-06-20T18:00:00"` will delay the job execution until 20th June 2020 at 6pm GMT.
 * `START_AT = "2020-06-20T18:00:00+02:00"` will delay the job execution until 20th June 2020 at 6pm GMT+02:00.

`START_AT` can be defined at *job-level* (delay the execution of the whole job) or at  *task-level* (delay the execution of a single task).

==== PARENT_JOB_ID

The `PARENT_JOB_ID` Generic Information is set automatically by ProActive when the current job has been submitted from another workflow using the <<../user/ProActiveUserGuide.adoc#_scheduler_api,Scheduler API>>.
It contains the id of the parent job which submitted the current job.

`PARENT_JOB_ID` is defined at *job-level*

==== NODE_ACCESS_TOKEN

The `NODE_ACCESS_TOKEN` Generic Information can be used to execute a task or all tasks of a workflow to specific nodes restricted by tokens.

The value of `NODE_ACCESS_TOKEN` must contain the token value. Workflows or tasks with `NODE_ACCESS_TOKEN` enabled will run exclusively on nodes containing the token.

See <<../admin/ProActiveAdminGuide.adoc#_policy_common_parameters,Node Source Policy Parameters>> for further information on node token restrictions.

`NODE_ACCESS_TOKEN` can be defined at *job-level* (applies to all tasks of a workflow) or at  *task-level* (applies to a single task).

==== Email

Email notifications on job events can be enabled on workflows using the following generic information:

`EMAIL`: contains the email address(es) of recipient(s) which should be notified.

`NOTIFICATION_EVENTS`: contains the set of events which should trigger a notification.

These generic information can be defined at *job-level* only.

See <<../user/ProActiveUserGuide.adoc#_get_notifications_on_job_events,Get Notifications on Job Events>> for further information.


==== REMOVE_DELAY

The `REMOVE_DELAY` generic information can be used to control when a job is removed from the scheduler database after its termination.

The <<../admin/ProActiveAdminGuide.adoc#_housekeeping,housekeeping mechanism>> must be configured to allow usage of `REMOVE_DELAY`.

`REMOVE_DELAY` overrides the global `pa.scheduler.core.automaticremovejobdelay` setting for a particular job.
It allows a job to be removed either *before* or *after* the delay configured globally on the server.

The general format of the `REMOVE_DELAY` generic information is `VVd XXh YYm ZZs`, where VV contain days, XX hours, YY minutes and ZZ seconds.

The format allows flexible combinations of the elements:

 * `12d 1h 10m`: 12 days, 1 hour and 10 minutes.
 * `26h`: 26 hours.
 * `120m 12s`: 120 minutes and 12 seconds.

`REMOVE_DELAY` can be defined at *job-level* only.

==== REMOVE_DELAY_ON_ERROR

The `REMOVE_DELAY_ON_ERROR` generic information can be used to control when a job is removed from the scheduler database after its termination, if the job has terminated with errors.

The <<../admin/ProActiveAdminGuide.adoc#_housekeeping,housekeeping mechanism>> must be configured to allow usage of `REMOVE_DELAY_ON_ERROR`.

`REMOVE_DELAY_ON_ERROR` overrides the global `pa.scheduler.core.automaticremove.errorjob.delay` setting for a particular job.
It allows a job to be removed either *before* or *after* the delay configured globally on the server.

The general format of the `REMOVE_DELAY_ON_ERROR` generic information is `VVd XXh YYm ZZs`, where VV contain days, XX hours, YY minutes and ZZ seconds.

The format allows flexible combinations of the elements:

* `12d 1h 10m`: 12 days, 1 hour and 10 minutes.
* `26h`: 26 hours.
* `120m 12s`: 120 minutes and 12 seconds.

`REMOVE_DELAY_ON_ERROR` can be defined at *job-level* only.

==== Earliest Deadline First Policy

The <<../admin/ProActiveAdminGuide.adoc#_earliest_deadline_first_edf_policy,Earliest Deadline First Policy>> is a <<../admin/ProActiveAdminGuide.adoc#_scheduling_policies,Scheduling Policy>> which can be enabled in the ProActive Scheduler server.

When enabled, this policy uses the following generic information to determine jobs deadlines and expected duration:

 * `JOB_DDL`: represents the job deadline in absolute (e.g. `2018-08-14T08:40:30+02:00`) or relative to submission (e.g. `+4:30`) format.
 * `JOB_EXEC_TIME`: represents job expected execution time in the format HH:mm:ss, mm:ss or ss (e.g. `4:30`)

See <<../admin/ProActiveAdminGuide.adoc#_earliest_deadline_first_edf_policy,Earliest Deadline First Policy>> for further information.

`JOB_DDL` and `JOB_EXEC_TIME` can be defined at *job-level* only.

==== REQUIRED_LICENSES

The <<../admin/ProActiveAdminGuide.adoc#_license_policy,License Policy>> is a <<../admin/ProActiveAdminGuide.adoc#_scheduling_policies,Scheduling Policy>> which can be enabled in the ProActive Scheduler server.

When enabled, this policy uses the `REQUIRED_LICENSES` generic information to determine which software licenses are consumed by the job or by the task.

`REQUIRED_LICENSES` is a comma-separated list of software names, which must match the names set in the <<../admin/ProActiveAdminGuide.adoc#_license_policy,License Policy>> configuration.

`REQUIRED_LICENSES` can be defined at *job-level* or *task-level*.

==== MAX_NODES_USAGE

The <<../admin/ProActiveAdminGuide.adoc#_node_usage_policy,Node Usage Policy>> is a <<../admin/ProActiveAdminGuide.adoc#_scheduling_policies,Scheduling Policy>> which can be enabled in the ProActive Scheduler server.

When enabled, this policy uses the `MAX_NODES_USAGE` generic information to determine how many Nodes a job and all its sub-jobs can use in parallel.

`MAX_NODES_USAGE` expects an integer value containing the number of parallel Nodes. When enabled on a job, `MAX_NODES_USAGE` will be implicitly applied to all sub-jobs.
For example, if _job_A_ defines _MAX_NODES_USAGE=10_ and is currently using 4 Nodes, then _job_B_ and _job_C_ both children of _job_A_, can use a total of 6 Nodes in parallel.

A sub-job can override this behavior by setting `MAX_NODES_USAGE` in its definition, either to:

 * a positive value. In that case, the sub-job will still have a maximum Node usage limit, but independently from its ancestor.
 * a negative value. In that case, the sub-job will have no maximum Node usage limit.

`MAX_NODES_USAGE` can be defined at *job-level* only.

==== DISABLE_PTK

The `DISABLE_PTK` Generic Information can be used to prevent the *Process Tree Killer* from running after a task execution.

Disabling the Process Tree Killer is mostly useful when a task requires to start a backgroud process which must remain alive after the task terminates.

Simply define a `DISABLE_PTK=true` generic information on any given task to prevent the Process Tree Killer from running.

More information is available in the link:../admin/ProActiveAdminGuide.html#_task_termination_behavior[Task Termination Behavior] section.

`DISABLE_PTK` can be defined at *task-level* only.

==== WALLTIME

The `WALLTIME` Generic Information can be used to enforce a *maximum execution time* for a task, or all tasks of a workflow.

The general format of the walltime attribute is `[hh:mm:ss]`, where h is hour, m is minute and s is second.
The format still allows for more flexibility. We can define the walltime simply as `5` which corresponds to
5 seconds, `10` is 10 seconds, `4:10` is 4 minutes and 10 seconds, and so on.

[NOTE]
====
When used at job-level, the configured walltime will not be applied to the workflow globally but to each individual task of the workflow.

For example, if the walltime is configured at job-level to be ten minutes, each task of the workflow can run no more than ten minutes, but the workflow itself has no time limitation.
====

As the walltime can also be configured directly in the workflow (xml attribute) or globally on the scheduler server (scheduler property), an order of priority applies.

More information is available in the link:../user/ProActiveUserGuide.html#_maximum_execution_time_for_a_task[Maximum execution time for a task] section.

`WALLTIME` can be defined at *job-level* or *task-level*.

==== PRE_SCRIPT_AS_FILE

The `PRE_SCRIPT_AS_FILE` Generic Information can be used to store a task pre-script into a file and skip its execution.
It can be used for example to embed inside a workflow a data file or a file written in a script language not supported by ProActive tasks and delegate its execution to a command-line interpreter.

More information is available in the <<_save_script>> section.

`PRE_SCRIPT_AS_FILE` can be defined at *task-level* only.

[[_node_source_generic_info]]
==== NODE_SOURCE

`NODE_SOURCE` is a multipurpose generic information which allows selecting only nodes that belong to the specified _Node Source_.

Other than selecting nodes, it allows also the dynamic provisioning of nodes when the selected Node Source is controlled by a <<../admin/ProActiveAdminGuide.adoc#_dynamic_policy,Dynamic Policy>> or is a
<<../admin/ProActiveAdminGuide.adoc#_execute_tasks_on_a_native_scheduler_node_source,Native Scheduler Node Source>>.

`NODE_SOURCE` should be preferred to using <<_native_scheduler,NS>> or <<_nodesourcename,NODESOURCENAME>> generic information.

Example usages:

 * `NODE_SOURCE=LocalNodes` => the task will run exclusively on nodes that belong to the _LocalNodes_ node source.
 * `NODE_SOURCE=AzureNodeSource` => will dynamically provision nodes in _AzureNodeSource_ (here _AzureNodeSource_ refer to an _AzureInfrastructure_ node source controlled by a _DynamicPolicy_) and run the task in the provisioned node.
 * `NODE_SOURCE=SlurmNodeSource` => will dynamically provision nodes in a Slurm cluster attached to _SlurmNodeSource_ (here _SlurmNodeSource_ refer to a _NativeSchedulerInfrastructure_ node source) and run the task in the provisioned node.

`NODE_SOURCE` can be defined at *job-level* (applies to all tasks of a workflow) or at  *task-level* (applies to a single task).

==== Native Scheduler

`NS` (short for *Native Scheduler*), `NS_BATCH` and `NS_PRE` are Generic Information used to deploy and configure workflow tasks inside a *Native Scheduler infrastructure*.

 * `NS`: execute a task associated with this generic information inside a ProActive Node Source interacting with a native scheduler.
The Node Source will dynamically deploy a Node to execute a task marked with this generic information.
*Deprecated*, consider using <<_node_source_generic_info>> instead.
The value of this generic information can be:
   - equal to the node source name. Example: `NS=Slurm`.
   - `true` to select any Native Scheduler node source.
   - `false` to disallow executing the task on a Native Scheduler node source.
 * `NS_BATCH`: allows providing additional parameters to the native scheduler. Example: `NS_BATCH=-q queue1 -lnodes=2:ppn=2`.
 * `NS_PRE`: allows providing a single line command which will be executed before the ProActive Node on the cluster. Example: `NS_PRE=module load mpi/gcc/openmpi-1.6.4`.

See <<../admin/ProActiveAdminGuide.adoc#_execute_tasks_on_a_native_scheduler_node_source,Execute Tasks on a Native Scheduler Node Source>> for more information.

`NS`, `NS_BATCH` and `NS_PRE` can be defined at *job-level* (applies to all tasks of a workflow) or at *task-level* (applies to a single task).

==== NODESOURCENAME

`NODESOURCENAME` is used to deploy workflow tasks in a Node Source controlled by a *Dynamic Policy*.
The Node Source will dynamically deploy a Node to execute a task marked with this generic information.

*Deprecated*, consider using <<_node_source_generic_info>> instead.

See <<../admin/ProActiveAdminGuide.adoc#_dynamic_policy,Dynamic Policy>> for more information.

`NODESOURCENAME` can be defined at *job-level* (applies to all tasks of a workflow) or at  *task-level* (applies to a single task).

==== RESOURCE_TAGS

`RESOURCE_TAGS` is used to assign tags to compute instances deployed in a Node Source controlled by a *Dynamic Policy*.

RESOURCE_TAGS format is a json key/value structure, such as:

[source, json]
----
{
  "tagName1" :  "tagValue1",
  "tagName2" :  "tagValue2"
}
----

The Node Source will forward these tags to the <<../admin/ProActiveAdminGuide.adoc#_node_source_infrastructures,Node Source Infrastructure>>.
The way these tags will be added to compute resources depends on the infrastructure.
Currently, only the <<../admin/ProActiveAdminGuide.adoc#_azure_scale_set_infrastructure,Azure Scale Set Infrastructure>> supports tags assignment.

See <<../admin/ProActiveAdminGuide.adoc#_dynamic_policy_resource_tagging,Dynamic Policy Resource Tagging>> and <<../admin/ProActiveAdminGuide.adoc#_scale_set_tagging,Scale Set Tagging>> for more information.

`RESOURCE_TAGS` can be defined at *job-level* (applies to all tasks of a workflow) or at  *task-level* (applies to a single task).


==== Documentation

The `Documentation` generic information allows to associate an html documentation with a workflow.
Its value must contain an URL pointing to the workflow documentation.

`Documentation` can be defined at *job-level* only.

The `task.documentation` generic information allows to associate an html documentation with a task.
Its value must contain an URL pointing to the task documentation.

`task.documentation` can be defined at *task-level* only.

`Documentation` and `task.documentation` values can also be a relative path.
In that case, the html file containing the documentation must be put inside `SCHEDULER_HOME/dist/war/getstarted/doc`.

==== Icon Management

There are specific generic information that are dedicated to icon management.
The icon of a workflow is specified inside the *job-level* Generic Information using the keyword `workflow.icon`.
The icon of a task is specified inside  *task-level* Generic Information using the keyword `task.icon`.

These generic information are used in ProActive portals for proper visualization of workflow and task icons.

The value of these generic information can contain either a url or a path to the icon.
ProActive server stores by default workflow icons in `SCHEDULER_HOME/dist/war/automation-dashboard/styles/patterns/img/wf-icons/`.

Example value with the default icon path: `/automation-dashboard/styles/patterns/img/wf-icons/postgresql.png`

==== Result Metadata

The following generic information can be used to assign result metadata to a workflow task.

Can only be used if the task result content is an array of bytes.

 * `content.type`: define the MIME type of the result.
 * `file.name`: allows to store (Save as) the result from the scheduler or workflow-automation portals as a specific file name.
 * `file.extension`: allows to store (Save as) the result from the scheduler or workflow-automation portals as a specific file extension with auto-generated file name.

See <<../user/ProActiveUserGuide.adoc#_assigning_metadata_to_task_result,Assigning metadata to task result>> for further information.

Result metadata generic information can be defined at *task-level* only.

==== PYTHON_COMMAND

When using <<../user/ProActiveUserGuide.adoc#_python,CPython>> tasks, the `PYTHON_COMMAND` generic information can be used to define the command starting the python interpreter.

The interpreter is started by default using the `python` command, but this generic information can be defined to use for example `python3`.

See <<../user/ProActiveUserGuide.adoc#_python,Python script language>> for further information.

`PYTHON_COMMAND` generic information should be defined at *task-level* but can be defined at job-level to apply to all workflow tasks.

==== Docker Compose options

When using <<../user/ProActiveUserGuide.adoc#_docker_compose,Docker Compose>> tasks, the following generic information can be used to control options given to `docker-compose` commands:

 * `docker-compose-options`: general parameters given to the docker-compose command.
 * `docker-compose-up-options`: options given to the `docker-compose up` command.
 * `docker-compose-options-split-regex`: declare a string to be used as options separator.

See <<../user/ProActiveUserGuide.adoc#_docker_compose,Docker Compose script language>> for further information.

The Docker Compose generic information should be defined at *task-level* but can be defined at job-level to apply to all workflow tasks.

==== Dockerfile options

When using <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile>> tasks, the following generic information can be used to control options given to `docker` commands:

* `docker-actions`: actions to perform. A comma separated list of possible actions (build, run, exec, stop, rmi). Default is `build,run,stop,rmi`.
* `docker-image-tag`: tag identifying the docker image. Default is `image_${PA_JOB_ID}t${PA_TASK_ID}`
* `docker-container-tag`: tag identifying the docker container. Default is `container_${PA_JOB_ID}t${PA_TASK_ID}`
* `docker-build-options`: options given to the `docker build` command.
* `docker-run-options`: options given to the `docker run` command.
* `docker-exec-command`: command given to `docker exec`, if used in `docker-actions`. If the command contains spaces, `docker-file-options-split-regex` should be used to split command parameters.
* `docker-exec-options`: options given to the `docker exec` command. Default is `-t` (which should always be included).
* `docker-stop-options`: options given to the `docker stop` command.
* `docker-rm-options`: options given to the `docker rm` command.
* `docker-rmi-options`: options given to the `docker rmi` command.
* `docker-file-options-split-regex`: declare a string to be used as options separator, instead of the `space` character.

See <<../user/ProActiveUserGuide.adoc#_dockerfile,Dockerfile script language>> for further information.

The Dockerfile generic information should be defined at the *task level*. Some (docker-file-options-split-regex, or command options) may be defined at the *job level* to apply to all tasks of the workflow.

==== Job Planner
The <<../JobPlanner/JobPlannerUserGuide.html#_all_doc_jp_user_guide, Job Planner>> automatically adds two generic information to the jobs it submits:

* `calendar.name`: the calendar name based on which the job is planned.
* `next.execution`: the next execution date of the planned job. The date is formatted with respect to the pattern `yyyy-MM-dd HH:mm:ss z` and considers the time zone specified in the Job Planner configuration.
When no time zone is specified, the default time zone of ProActive server is considered.

==== Submission.mode

The *Submission Mode* allows keeping track from where a Job has been submitted.
It can have values in:

* *Interactive Submissions:* `studio`, `catalog`, `workflow-execution`, `scheduler-portal`
* *Automated Submissions:* `job-planner`, `service-automation`, `event-orchestration`
* *API Submissions:* `workflow-api`, `cli`, `rest-api`
* *Custom:* `user-defined value`, to differentiate application-specific submissions.

It is implemented with the *submission.mode* Generic Information that records the information.

When submitting a workflow from one of the portals (Studio, Scheduler, Workflow Execution, Catalog, etc.), or when using one of the ProActive submission services (Job Planner, Service Automation, Event Orchestration) this Generic Information is automatically defined by the system, using the standardized values.

When a workflow is submitted from a third-party component (such as a company service), one can set this Generic Information value to a meaningful custom name, that will help identify the origin from which the workflow has been submitted.

The Submission Mode can be seen synthetically in the  <<_glossary_health_dashboard,Health Dashboard>> for a selected time-frame in the widget “Submission Mode”, including custom values.

The Submission Mode can also be seen:

* In *Workflow Execution*: the user can see the value in the Generic Information section of the detailed Job info.
* In *Scheduler Portal*: the value is displayed in “Submitted from” column of the Job table, and in the Job info tab.