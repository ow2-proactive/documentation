:docinfo:
:toc:
:toc-title: PWS User Guide
= ProActive Workflows & Scheduling -- User Guide
include::../common-settings.adoc[]
include::../all-doc-links.adoc[]

== Overview

include::../Overview.adoc[]

=== Glossary

include::../Glossary.adoc[]

== Get started

To submit your first computation to *ProActive Scheduler*, link:../admin/ProActiveAdminGuide.html#_getting_started[install] it in
your environment (default credentials: admin/admin) or just use our demo platform https://try.activeeon.com[try.activeeon.com^].

*ProActive Scheduler* provides comprehensive interfaces that allow to:

- +++Create workflows using <a class="studioUrl" href="/studio" target="_blank">ProActive Workflow Studio</a>+++
- +++Submit workflows, monitor their execution and retrieve the tasks results using <a class="schedulerUrl" href="/scheduler" target="_blank">ProActive Scheduler Portal</a>+++
- +++Add resources and monitor them using <a class="rmUrl" href="/rm" target="_blank">ProActive Resource Manager Portal</a>+++
- +++Version and share various objects using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/catalog-portal" target="_blank">ProActive Catalog Portal</a>+++
- +++Provide an end-user workflow submission interface using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/workflow-automation" target="_blank">Workflow Automation Portal</a>+++
- +++Generate metrics of multiple job executions using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/job-analytics" target="_blank">Job Analytics Portal</a>+++
- +++Plan workflow executions over time using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/job-planner-execution-planning" target="_blank">Job Planner Portal</a>+++
- +++Add services using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/cloud-automation" target="_blank">Cloud Automation Portal</a>+++
- +++Perform event based scheduling using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/cloud-watch" target="_blank">Cloud Watch Portal</a>+++
- +++Control manual workflows validation steps using <a class="automationDashboardUrl" href="/automation-dashboard/#/portal/notification-portal" target="_blank">Notification Portal</a>+++

We also provide a +++<a class="restUrl" href="/rest" target="_blank">REST API</a>.+++ and <<../user/ProActiveUserGuide.adoc#_scheduler_command_line,command line interfaces>> for advanced users.

== Create and run your computation

=== Jobs, workflows and tasks

In order to use Scheduler for executing various computations, one needs to write the execution definition
also known as the Workflow definition. A workflow definition is an XML file that adheres to
<<_job_and_task_specification,XML schema for ProActive Workflows>>.

It specifies a number of XML tags for specifying execution steps, their sequence and dependencies.
Each execution step corresponds to a task which is the smallest unit of execution that can be performed on a
 computation resources (ProActive Node). There are several types of tasks which caters different use cases.

==== Task Types
*ProActive Scheduler* currently supports three main types of tasks:

- <<_native_tasks,*Native Task*>>, a command with eventual parameters to be executed
- <<_script_tasks,*Script Task*>>, a script written in Groovy, Ruby, Python and other languages supported by the JSR-223
- <<_java_tasks,*Java Task*>>, a task written in Java extending the Scheduler API

For instance, a *Script
Task* can be used to execute an inline script definition or a script file as an execution step whereas a
*Native Task* can be used to execute a native executable file.

TIP: We recommend to use script tasks that are more flexible rather than Java tasks.
You can easily integrate with any Java code from a Groovy script task.

==== Additional Scripts
In addition to the *main definition* of a Task, scripts can also be used to provide additional *actions*.
The following actions are supported:

* one or more <<_selection,selection scripts>> to control the Task resource (ProActive Node) selection.
* a <<_fork_environment,fork environment script>> script to control the Task execution environment (a separate Java Virtual Machine or Docker container).
* a <<_pre_post_clean,pre script>> executed immediately before the main task definition (and inside the forked environment).
* a <<_pre_post_clean,post script>> executed immediately after the main task definition if and only if the task did not trigger any error (also run inside the forked environment).
* a <<_control_flow_scripts,control flow script>> executed immediately after the post script (if present) or main task definition to control flow behavior such as <<_branch,branch>>, <<_loop,loop>> or <<_replicate,replicate>> (also run inside the forked environment).
* finally, a <<_pre_post_clean,clean script>> executed after the task is finished, whether the task succeeded or not, and directly on the ProActive Node which hosted the task.

==== Task Dependencies

A workflow in ProActive Workflows & Scheduling can be seen as an *oriented graph of Tasks*:

image::flow_spec_dependency.png[align="center"]

In this tasks graph, we see that task 4 is preceded by task 1, this
means that the ProActive Scheduler will wait for the end of task 1 execution before launching task
4. In a more concrete way, task 1 could be the calculation of a part of
the problem to solve, and task 4 takes the result provided by task 1 and
compute another step of the calculation. We introduce here the concept
of passing data between tasks. This relation is
called a <<_dependency>>, and we say that task 4 **depends** on task 1.

We see that task 1, 2 and 3 are not linked, so these three tasks can be
executed in **parallel**, because they are independent from each other.

The task graph is defined by the user at the time of workflow creation, but can also be modified dynamically during
 the job execution by control flow actions such as <<_replicate>>.

A *finished job* contains the results and logs of each task. Upon failure,
a task can be restarted automatically or cancelled.

=== Native Tasks

A *Native Task* is a ProActive Workflow task which main execution is defined as a *command to run*.

Native tasks are the simplest type of Task, where a user provides a *command* with a list of *parameters*.

Using native tasks, one can easily reuse existing applications and embed them in a workflow.

Once the executable is wrapped as a task you can easily leverage some of the workflow constructs to run your
executable commands in parallel.

You can find an example of such integration in this
link:examples/native_task.xml[XML workflow^] or you can also build one yourself using the
*Workflow Studio*.

Native application by nature can be tied to a given operating system so
if you have heterogeneous nodes at your disposal, you might need to select a suitable node to run your native task.
This can be achieved using <<_selection,selection script>>.

NOTE:  Native Tasks are not the only possibility available to run executables or commands, this can also be achieved using shell language <<_script_tasks,script tasks>>.

=== Script Tasks

A *Script Task* is a ProActive Workflow task which main execution is defined as a *script*.

ProActive Workflows supports tasks in many scripting languages. The currently supported dynamic languages or backends are
link:http://groovy-lang.org/[Groovy, window="_blank"],
link:https://www.jython.org[Jython, window="_blank"],
link:https://www.python.org/[Python, window="_blank"],
link:https://jruby.org[JRuby, window="_blank"],
link:https://docs.oracle.com/javase/8/docs/technotes/guides/scripting/index.html#jsengine[Javascript, window="_blank"],
link:https://www.scala-lang.org/[Scala, window="_blank"],
link:https://docs.microsoft.com/fr-fr/powershell/scripting/overview?view=powershell-5.0[Powershell, window="_blank"],
link:https://en.wikipedia.org/wiki/VBScript[VBScript, window="_blank"],
link:https://www.r-project.org/[R, window="_blank"],
link:https://www.perl.org/[Perl, window="_blank"],
link:https://www.gnu.org/software/bash/[Bash, window="_blank"],
link:https://en.wikipedia.org/wiki/Unix_shell[Any Unix Shell, window="_blank"],
link:https://en.wikipedia.org/wiki/Cmd.exe[Windows CMD, window="_blank"],
link:https://docs.docker.com/engine/reference/builder/[Docker File, window="_blank"],
link:https://docs.docker.com/compose/compose-file/[Docker Compose, window="_blank"] and
link:https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/[Kubernetes, window="_blank"].

NOTE: Though `Docker File`, `Docker Compose` and `Kubernetes` are not really scripting language but rather description languages, ProActive tasks can interpret Docker files, Docker Compose or Kubernetes yaml files to start containers or pods.

As seen in the list above, *Script Tasks* can be used to run native operating system commands by providing a script written in `bash`, `ksh`, `windows cmd`, `Powershell`, etc...
Simply set the language attribute to `bash`, `shell`, or `cmd`  and type your command(s) in the workflow.
In this sense, it can replace in most cases a *Native Task*.

TIP: You can easily embed small scripts in your workflow.
The nice thing is that the workflow will be self-contained and will not require to compile your code before executing. However, we
recommend that you keep these scripts small to keep the workflow easy to understand.


You can find an example of a script task in this
link:examples/script_task.xml[XML workflow^] or you can also build one yourself using the
*Workflow Studio*. The link:https://try.activeeon.com/tutorials/quickstart/quickstart.html[quickstart tutorial, window="_blank"]
relies on script tasks and is a nice introduction to writing workflows.

Scripts can also be used to decorate any kind of task (*Script*, *Java* or *Native*) with specific actions, as described in the <<_additional_scripts,additional scripts section>>.

It is thus possible to combine various scripting languages in a single Task. For example a *pre* script could be written in `bash` to transfer some files from a remote file system, while the main script will be written in `python` to process those files.

Finally, a *Script Task* may or may not return a result materialized by the <<_task_result,`result`>> <<_script_bindings, script binding>>.

==== Script Bindings

A *Script Task* or <<_additional_scripts,additional scripts>> can use automatically-defined <<_glossary_script_bindings,script bindings>>.
These bindings allow to associate the script inside its *workflow context*, for example, the ability to know the current *workflow variables* as submitted by a user, the workflow *job id* as run inside the ProActive Scheduler, etc.

Bindings allow as well to pass information between various scripts *inside the same task* or *across different tasks*.

A *script binding* can be either:

 * Defined automatically by the ProActive Scheduler before the script starts its execution. In this case, we call it also a _provided_ or _input script binding_.
 * Needed to be defined by the script during its execution to provide meaningful results. In this case, we call it also a _result_ or _output script binding_.

Below is an example of Script Task definition which uses both types of bindings:

[source,groovy]
----
jobId = variables.get("PA_JOB_ID")
result = "The Id of the current job is: " + jobId
----

As we can see, the `variables` binding in provided automatically by the ProActive Scheduler before the script execution and it is used to compute a `result` binding as task output.

Bindings are stored internally inside the ProActive Scheduler as *Java Objects*. Accordingly, a *conversion* may be performed when targetting (or when reading from) other languages.

For example, <<_generic_information,Generic Information>> or <<_variables,Workflow Variables>> are stored as Java objects implementing the link:https://docs.oracle.com/javase/8/docs/api/java/util/Map.html[Map interface].
When creating the `variables` or `genericInformation` bindings prior to executing a Groovy, JRuby, Jython or Python script, the ProActive Scheduler will convert it to various types accepted by the target language.
In those languages, printing the type of the `genericInformation` binding will show:

----
Groovy: class com.google.common.collect.RegularImmutableBiMap
JRuby: Java::ComGoogleCommonCollect::RegularImmutableBiMap
Jython: <type 'com.google.common.collect.RegularImmutableBiMap'>
Python: <class 'py4j.java_collections.JavaMap'>
----
We see here that Groovy, JRuby and Jython did not perform any conversion, whereas Python (CPython) did.
This behavior is expected as CPython script execution is run as a standalone python process and a custom type conversion occurs while the formers are run directly inside the task Java Virtual Machine will full Java type compatibility.

Depending on the script type (task script, selection script, etc...), the script may need to define an *output binding* to return some information to the scheduler.

Below are some examples of *output bindings* for various kind of scripts:

* `result` and `resultMetadata` for a Script Task main execution script.
* `selected` for a selection script.
* `loop` for a Loop construct flow script.
* `runs` for a Replicate construct flow script.

The complete list of script bindings (both input and output) is available in the <<_variables_quick_reference,Script Bindings Reference>> section.

Below are descriptions of some specific scripting language support, which can be used in Script Tasks main execution script or in any Task <<_additional_scripts,additional scripts>>.

=== Java Tasks

A workflow can execute Java classes thanks to *Java Tasks*.
In terms of XML definition, a Java Task consists of a *fully-qualified class name* along with *parameters*:

[source,xml]
----
<task name="Java_Task">
  <javaExecutable class="org.ow2.proactive.scheduler.examples.WaitAndPrint">
    <parameters>
      <parameter name="sleepTime" value="20"/>
      <parameter name="number" value="2"/>
    </parameters>
  </javaExecutable>
</task>
----

The provided class must extend the link:../javadoc/index.html?org/ow2/proactive/scheduler/common/task/executable/JavaExecutable.html[JavaExecutable] abstract class and implement the link:../javadoc/org/ow2/proactive/scheduler/common/task/executable/JavaExecutable.html#execute-org.ow2.proactive.scheduler.common.task.TaskResult...-[execute] method.

Any parameter must be defined as public attributes. For example, the above *WaitAndPrint* class contains the following attributes definitions:

[source,Java]
----
/** Sleeping time before displaying. */
public int sleepTime;

/** Parameter number. */
public int number;
----

A parameter conversion is performed automatically by the *JavaExecutable* super class. If this automatic conversion is not suitable, it is possible to override the link:../javadoc/org/ow2/proactive/scheduler/common/task/executable/JavaExecutable.html#init-java.util.Map-[init] method.

Finally, several utility methods are provided by *JavaExecutable* and should be used inside *execute*. A good example is link:../javadoc/org/ow2/proactive/scheduler/common/task/executable/JavaExecutable.html#getOut--[getOut] which allows writing some textual output to the workflow task or link:../javadoc/org/ow2/proactive/scheduler/common/task/executable/JavaExecutable.html#getLocalSpace--[getLocalSpace] which allows access to the task execution directory.

The complete code for the *WaitAndPrint* class is available below:

[source,Java]
----
public class WaitAndPrint extends JavaExecutable {

    /** Sleeping time before displaying. */
    public int sleepTime;

    /** Parameter number. */
    public int number;

    /**
     * @see JavaExecutable#execute(TaskResult[])
     */
    @Override
    public Serializable execute(TaskResult... results) throws Throwable {
        String message = null;

        try {
            getErr().println("Task " + number + " : Test STDERR");
            getOut().println("Task " + number + " : Test STDOUT");

            message = "Task " + number;
            int st = 0;
            while (st < sleepTime) {
                Thread.sleep(1000);
                try {
                    setProgress((st++) * 100 / sleepTime);
                } catch (IllegalArgumentException iae) {
                    setProgress(100);
                }
            }

        } catch (Exception e) {
            message = "crashed";
            e.printStackTrace(getErr());
        }

        getOut().println("Terminate task number " + number);

        return ("No." + this.number + " hi from " + message + "\t slept for " + sleepTime + " Seconds");
    }

}
----

=== Run a workflow

To run a workflow, the user submits it to the *ProActive Scheduler*.
It will be possible to choose the values of all Job Variables when submitting the workflow (see section <<_job_variables,Job Variables>>).
A verification is performed to ensure the well-formedness of the workflow.
A verification will also be performed to ensure that all variables are valid according to their model definition (see section <<_variable_model,Variable Model>>).
Next, a job is created and inserted into the pending queue and
waits until free resources become available.
Once the required resources are provided by the ProActive Resource Manager, the job is started. Finally,
once the job is finished, it goes to the queue of finished
jobs where its result can be retrieved.

You can submit a workflow to the Scheduler using the *Workflow Studio*, the Scheduler Web Interface or <<_scheduler_command_line,command
line tools>>. For advanced users we also expose REST and JAVA APIs.

TIP: During the submission, you will be able to edit <<_workflow_variables>>, so you can effectively use
them to parameterize workflow execution and use workflows as <<_templating,templates>>.

[[_states]]
==== Job & Task states

During their execution, jobs go through different states.
The screenshot below shows Pending and Current Jobs states summary as seen in Workflow Automation portal.

image::current_job_states.png[align="center", width=350]

.Job States for Pending and Current Jobs
[cols="17%,17%,66%", options="header"]
|===
| State | Name | Description
| `PENDING` | Pending | The job is waiting to be scheduled. None of its tasks have been Running so far.
| `RUNNING` | Running | The job is running. At least one of its task has been scheduled.
| `STALLED` | Stalled | The job has been launched but no task is currently running.
| `PAUSED` | Paused | The job is paused waiting for user to resume it.
| `IN_ERROR` | In-Error | The job has one or more In-Error tasks that are suspended along with their dependencies. User intervention is required to fix the causing issues and restart the In-Error tasks to resume the job.

|===

The screenshot below shows Past Jobs states summary as seen in Workflow Automation portal.

image::past_job_states.png[align="center", width=350, title-align="center"]

.Job States for Past Jobs
[cols="17%,17%,66%", options="header"]
|===
| State | Name | Description
| `FINISHED` | Finished | The job is finished. Tasks are finished or faulty.
| `CANCELED` | Cancelled | The job has been canceled because of an exception.
This status is used when an exception is thrown by the user code of a task and when the user has asked to cancel the job on exception.
| `FAILED` | Failed | The job has failed. One or more tasks have failed (due to resources failure).
There is no more executionOnFailure left for a task.
| `KILLED` | Killed | The job has been killed by the user.

|===


Similarly to jobs, during their execution, tasks go through different states.

.Task States
[cols="17%,17%,66%", options="header"]
|===
| State | Name | Description |
 `ABORTED` | Aborted | The task has been aborted by an exception on an other task while the task is running. (job is cancelOnError=true).
 Can be also in this status if the job is killed while the concerned task was running. |
 `FAILED` | Resource down | The task is failed
(only if maximum number of execution has been reached and the node on which it was started is down).|
 `FAULTY` | Faulty | The task has finished execution with error code (!=0) or exception. |
 `FINISHED` | Finished | The task has finished execution. |
 `IN_ERROR` | In-Error | The task is suspended after first error, if the user has asked to suspend it. The task is waiting for a manual restart action. |
 `NOT_RESTARTED` | Could not restart | The task could not be restarted.
  It means that the task could not be restarted after an error
  during the previous execution. |
 `NOT_STARTED` | Could not start | The task could not be started.
  It means that the task could not be started due to
   dependencies failure.|
 `PAUSED` | Paused | The task is paused.|
 `PENDING` | Pending | The task is in the scheduler pending queue.|
 `RUNNING` | Running | The task is executing.|
 `SKIPPED` | Skipped | The task was not executed: it was the non-selected branch of an IF/ELSE control flow action. |
 `SUBMITTED` | Submitted | The task has just been submitted by the user.|
 `WAITING_ON_ERROR` | Faulty... | The task is waiting for restart after an error (i.e. native code != 0 or exception, and maximum number of execution is not reached).|
 `WAITING_ON_FAILURE` | Failed... | The task is waiting for restart after a failure (i.e. node down). |

|===

// TODO state diagram

==== Job Priority

A job is assigned a default priority of `NORMAL` but the user can increase or decrease the priority once the
job has been submitted. When they are scheduled, jobs with the highest priory are executed first.

The following values are available:

- `IDLE`
- `LOWEST`
- `LOW`
- `NORMAL`
- `HIGH` can only be set by an administrator
- `HIGHEST` can only be set by an administrator

=== Retrieve logs

It is possible to retrieve multiple logs from a job, these logs can either be:

- The standard _output/error logs_ associated with a job.
- The standard _output/error logs_ associated with a task.
- The scheduler _server logs_ associated with a job.
- The scheduler _server logs_ associated with a task.

Unless your account belongs to an administrator group, you can only see the logs of a job that you own.

==== Retrieve logs from the portal

- `Job standard output/error logs`: +
To view the standard output or error logs associated with a job, select a job from the job list and then on the _Output_ tab in the bottom right panel. +
Click on _Streaming Output_ checkbox to auto-fetch logs for running tasks of the entire Job. The logs panel will be updated as soon as new log lines will be printed by this job. +
You cannot select a specific Task in the streaming mode. If you activate streaming while some Tasks are already finished, you will get the logs of those Tasks as well. +
Click on _Finished Tasks Output_ button to retrieve logs for already finished tasks. For all the finished Tasks within the Job, or for the selected Task. +
The command does work when Job is still in Running state, as well as when Job is Finished. +
Logs are limited to 1024 lines. Should your job logs be longer, you can select the _Full logs (download)_ option from the drop down list.

- `Task standard output/error logs`: +
To view the standard output or error logs associated with a task, select a job from the job list and a task from the task list. +
Then in the _Output_ tab, choose _Selected task_ from the drop down list. +
Once the task is terminated, you will be able to click on the _Finished Tasks Output_ button to see the standard output or error associated with the task. +
It is not possible to view the streaming logs of single task, only the job streaming logs are available.

- `Job server logs`: +
Whether a job is running or finished, you can access the associated server logs by selecting a job, opening the _Server Logs_ tab in the bottom-right panel and then clicking on _Fetch logs_. +
Server logs contains debugging information, such as the job definition, output of selection or cleaning scripts, etc.

- `Task server logs`: +
In the _Server Logs_ tab, you can choose _Selected task_ to view the server logs associated with a single task.

==== Retrieve logs from the command line

The chapter <<_scheduler_command_line,command line tools>> explains how to use the command line interface.
Once connected, you can retrieve the various logs using the following commands. Server logs cannot be accessed from the command line.

- `Job standard output/error logs`: joboutput(jobid) +
----
> joboutput(1955)
[1955t0@precision;14:10:57] [2016-10-27 14:10:057 precision] HelloWorld
[1955t1@precision;14:10:56] [2016-10-27 14:10:056 precision] HelloWorld
[1955t2@precision;14:10:56] [2016-10-27 14:10:056 precision] HelloWorld
[1955t3@precision;14:11:06] [2016-10-27 14:11:006 precision] HelloWorld
[1955t4@precision;14:11:05] [2016-10-27 14:11:005 precision] HelloWorld
----
- `Task standard output/error logs`: taskoutput(jobid, taskname) +
----
> taskoutput(1955,'0_0')
[1955t0@precision;14:10:57] [2016-10-27 14:10:057 precision] HelloWorld
----

- `Streaming job standard output/error logs`: livelog(jobid)
----
> livelog(2002)
Displaying live log for job 2002. Press 'q' to stop.
> Displaying live log for job 2002. Press 'q' to stop.
[2002t2@precision;15:57:13] [ABC, DEF]
----

=== Retrieve results

Once a job or a task is terminated, it is possible to get its result. Unless you belong to the administrator group, you can only get the result of the job that you own.
Results can be retrieved using the Scheduler Web Interface or the command line tools.

NOTE: When running native application, the task result will be the exit code of the application. Results
usually make more sense when using script or Java tasks.

==== Retrieve results from the portal

In the scheduler portal, select a job, then select a task from the job's task list. Click on _Preview_ tab in the bottom-right panel.

In this tab, you will see two buttons:

- `Open in browser`: when clicking on this button, the result will be displayed in a new browser tab. By default, the result will be displayed in text format.
If your result contains binary data, it is possible to specify a different display mode using <<_assigning_metadata_to_task_result,Result Metadata>. +
If the task failed, when clicking on the _Open in browser_ button, the task error will be displayed.

- `Save as file`: when clicking on this button, the result will be saved on disk in binary format. By default, the file name will be generated automatically using the job and task ids, without an extension.
It is possible to customize this behavior and specify in the task a file name, or a file extension using <<_assigning_metadata_to_task_result,Result Metadata>>.

The following example gets one png image and add the metadata to help the browser display it and add a name when downloading.
----
file = new File(fileName)
result = file.getBytes()
resultMetadata.put("file.name", fileName)
resultMetadata.put("content.type", "image/png")
----

==== Retrieve results from the command line

The chapter <<_scheduler_command_line,command line tools>> explains how to use the command line interface.
Once connected, you can retrieve the task or job results:

- `Result of a single task`: taskresult(jobid, taskname)
----
> taskresult(2002, 'Merge')
task('Merge') result: true
----

- `Result of all tasks of a job`: jobresult(jobid)
----
> jobresult(2002)
job('2002') result:
Merge : true
Process*1 : DEF
Process : ABC
Split : {0=abc, 1=def}
----

== ProActive Studio
**ProActive Workflow Studio** is used to create and submit workflows graphically.
The Studio allows to simply drag-and-drop various task constructs and draw their dependencies to form complex workflows.
It also provides various flow control widgets such as conditional branch, loop, replicate etc to construct workflows with dynamic structures.

The studio usage is illustrated in the following example.

=== A simple example

The link:https://try.activeeon.com/tutorials/quickstart/quickstart.html[quickstart tutorial, window="_blank"] on link:https://try.activeeon.com[try.activeeon.com, window="_blank"]
shows how to build a simple workflow using script tasks.


Below is an example of a workflow created with the Studio:

image::GI_documentation_finance_url.png[align="center"]

In the left part, are illustrated the **General Parameters** of the workflow with the following information:

- `Name`: the name of the workflow.
- `Project`: the project name to which belongs the workflow.
- `Description`: the textual description of the workflow.
- `Documentation`: if the workflow has a Generic Information named "Documentation", then its URL value is displayed as a link.
- `Job Priority`: the priority assigned to the workflow. It is by default set to `NORMAL`, but can be increased or decreased once the job is submitted.

In the right part, we see the *graph of dependent tasks* composing the workflow. Each task can be selected to show the task specific attributes and defintions.

Finally, above the workflow graph, we see the various *palettes* which can be used to _drag & drop_ *sample task definitions* or *complex constructs*.

The link:../user/ProActiveUserGuide.html#_types_of_tasks[following chapters] describe the three main type of tasks which can be defined inside ProActive Workflows.

=== Use the ProActive Catalog from the Studio

The GUI interaction with the Catalog can be done in two places: the +++<a class="studioUrl" href="/studio" target="_blank">Studio</a>+++ and +++<a class="automationDashboardUrl" href="/automation-dashboard/#/portal/catalog-portal" target="_blank">Catalog Portal</a>+++.
The portals follow the concepts of the Catalog: Workflows are stored inside buckets, a workflow has some metadata and can have several revisions.

The Catalog view in the Studio or in the Catalog Portal allows to browse all the workflows in the Catalog grouped by buckets and to list all the revisions of a workflow along with their commit message.

Inside the Studio, there is a `Catalog` menu from which a user can directly interact with the Catalog to import or publish Workflows.

image::studio_catalog_menu.png[align=center]

Additionally, the Palette of the Studio lists the user's favourite buckets to allow easy import of workflows from the Catalog with a simple Drag & Drop.

image::studio-palette.png[align=center]

==== Publish current Workflow to the Catalog
Workflows created in the studio can be saved inside a bucket in the Catalog by using the `Publish current Workflow to the Catalog` action.
When saving a Workflow in the Catalog, users can add a specific `commit message`.
If a Workflow with the same name already exists in the specified bucket, a new revision of the Workflow is created.
We recommend to always specify commit messages at any commit for an easier differentiation between stored versions.

==== Get a Workflow from the Catalog
When the Workflow is selected from Catalog you have two options:

1. `Open as a new Workflow`: Open the Workflow from Catalog as a new Workflow in Studio.

2. `Append to current Workflow`: Append the selected Workflow from the Catalog to the Workflow already opened inside the Studio.

==== Add Bucket Menu to the Palette
The Palette makes it easier to use workflows stored in a specific Bucket of the Catalog as templates when designing a Workflow.

To add a bucket from the Catalog as a dropdown menu in the Palette:  Click on `View` → `Add Bucket Menu to the Palette` or you press the image:studio-palette-add.png[+, 32, 32] button in the palette.
A window will show up to ask you which bucket you want to add to the Palette as in the image below.

image::studio-catalog-main-menu3.png[align=center]

The selected `Data Connectors` Bucket now appears as a menu in the Studio. See the image below.

image::studio-catalog-main-menu4.png[align=center]

You can repeat the operation as many times as you wish in order to add other specific Menus you might need for your workflow design. See the image below.

image::studio-catalog-main-menu5.png[align=center]

==== Change Palette Preset
The Studio offers the possibility to set a Preset for the Palette. This makes it easier to load the Palette with a predefined set of default buckets.
Presets are generally arranged by theme (Basic Examples, Machine Learning, Deep Learning, Big Data, etc.)
The Palette's preset can be changed by clicking `View` → `Change Palette Preset`. This will show a window with the current list of presets as in the image below.

image::studio-catalog-main-menu1.png[align=center]

After changing the preset, its name appears at the top of the Studio and all its buckets are added to the Palette.

image::studio-catalog-main-menu2.png[align=center]

== Workflow concepts

Workflows comes with constructs that help you distribute your computation. The tutorial
https://try.activeeon.com/tutorials/adv.html[Advanced workflows^] is a nice introduction to workflows with
ProActive.

The following constructs are available:

- *Dependency*
- *Replicate*
- *Branch*
- *Loop*

TIP: Use the *Workflow Studio* to create complex workflows, it is much easier than writing XML!

=== Dependency

Dependencies can be set between tasks in a TaskFlow job. It provides a way to execute your tasks in a specified order,
but also to forward result of an ancestor task to its children as parameter. Dependency between tasks is then
both a temporal dependency and a data dependency.

image::flow_spec_dependency.png[align="center"]

Dependencies between tasks can be added either in *ProActive Workflow Studio* or simply in workflow XML as shown below:

[source, xml]
----
<taskFlow>
    <task name="task1">
        <scriptExecutable>
            <script>
                <code language="groovy">
                    println "Executed first"
                </code>
            </script>
        </scriptExecutable>
    </task>
    <task name="task2">
        <depends>
            <task ref="task1"/>
        </depends>
        <scriptExecutable>
            <script>
                <code language="groovy">
                    println "Now it's my turn"
                </code>
            </script>
        </scriptExecutable>
    </task>
</taskFlow>
----

[[_replicate]]
=== Replicate

The *replication* allows the execution of multiple tasks in parallel when only one task
is defined and the number of tasks to run could change.

image::flow_spec_duplicate.png[align=center]

-   The target is the direct child of the task initiator.

-   The initiator can have multiple children; each child is replicated.

-   If the target is a *start block*, the whole block is replicated.

-   The target must have the initiator as only dependency: the action is
    performed when the initiator task terminates. If the target has an
    other pending task as dependency, the behaviour cannot be specified.

-   There should always be a merge task after the target of a replicate:
    if the target is not a start block, it should have at least one
    child, if the target is a start block, the corresponding end block
    should have at least one child.

-   The last task of a replicated task block (or the replicated task if
    there is no block) cannot perform a *branching* or *replicate*
    action.

-   The target of a *replicate* action can not be tagged as *end block*.

- The current replication index (from to 0 to `runs`) can be accessed via the
`PA_TASK_REPLICATION` <<_workflow_variables,variable>>.

TIP: If you are familiar with programming, you can see the replication as forking tasks.

=== Branch

The *branch* construct provides the ability to choose between two alternative task flows,
with the possibility to merge back to a common flow.

image::flow_spec_if.png[align=center]

-   There is no explicit dependency between the initiator and the
    *if/else* targets. These are *optional links* (ie. A -> B or E ->
    F) defined in the *if* task.

-   The *if* and *else* flows can be merged by a *continuation* task
    referenced in the *if* task, playing the role of an *endif*
    construct. After the branching task, the flow will either be that of
    the *if* or the *else* task, but it will be continued by the
    *continuation* task.

-   *If* and *else* targets are executed *exclusively*. The initiator
    however can be the dependency of other tasks, which will be executed
    normally along the *if* or the *else* target.

-   A *task block* can be defined across *if*, *else* and *continuation*
    links, and not just plain dependencies (i.e. with *A* as *start* and
    *F* as *end*).

-   If using no continuation task, the if and else targets, along with
    their children, must be strictly distinct.

-   If using a continuation task, the if and else targets must be
    strictly distinct and valid task blocks.

-   *if*, *else* and *continuation* tasks (B, D and F) cannot have
    an explicit dependency.

-   *if*, *else* and *continuation* tasks cannot be entry points for the
    job, they must be triggered by the *if* control flow action.

-   A task can be target of only one *if* or *else* action. A
    *continuation* task can not merge two different *if* actions.

TIP: If you are familiar with programming, you can see the branch as a if/then/else.

=== Loop

The loop provides the ability to repeat a set of tasks.

image::flow_spec_loop.png[align=center]

-   The target of a *loop* action must be a parent of the initiator
    following the dependency chain; this action goes back to a
    previously executed task.

-   Every task is executed at least once; *loop* operates in a
    *do...while* fashion.

-   The target of a *loop* should have only one explicit dependency. It
    will have different parameters (dependencies) depending if it is
    executed for the first time or not. The cardinality should stay the
    same.

-   The *loop* scope should be a *task block*: the target is a *start
    block* task, and the initiator its related *end block task*.

- The current iteration index (from 0 to n until `loop` is false) can be accessed via the
    `PA_TASK_ITERATION` <<_workflow_variables,variable>>.

TIP: If you are familiar with programming, you can see the loop as a do/while.

=== Task Blocks

Workflows often relies on *task blocks*. Task blocks are defined by pairs of *start* and *end* tags.

-   Each task of the flow can be tagged either *start* or *end*

-   Tags can be nested

-   Each *start* tag needs to match a distinct *end* tag

Task blocks are very similar to the parenthesis of most programming
languages: anonymous and nested start/end tags. The only difference is
that a parenthesis is a syntactical information, whereas task blocks are
semantic.

The role of task blocks is to restrain the expressiveness of the system
so that a workflow can be statically checked and validated. A treatment
that can be looped or iterated will be isolated in a well-defined task
block.

-   A *loop* flow action only applies on a task block: the initiator of
 the loop must be the end of the block, and the target must be the
 beginning.

-   When using a *continuation* task in an *if* flow action, the *if*
 and *else* branches must be task blocks.

-   If the child of a *replicate* task is a task block, the whole block
 will be replicated and not only the child of the initiator.

=== Variables

include::./references/Variables.adoc[]

[[_task_result]]

=== Task result

Another way to propagate data from a task to another relies on *result* variable.
Anywhere in a task (usually at the end) you can set a value to a reserved
variable named *result*. This value will be available in tasks
depending on it. If a task has one or several dependencies, *results* will always be an array.

Assuming that we have two tasks *task1* and *task2* written in Groovy:

[source, groovy]
----
// task1
result = "task1";
----

[source, groovy]
----
// task2
result = "task2";
----

and *task3* that depends on tasks *task1* and *task2*, then, you can access result values defined by the parents as follows:

[source, groovy]
----
// task3
println(results[0]);
// will print "task1"
println(results[1]);
// will print "task2"
----

NOTE: results will be aggregated according to the order declared in the dependency list. Consequently, if the xml *depends* tag of *task3* contains the list [task1, task2] (see the xml example below), then results[0] will contain the result of *task1* and results[1] the result of *task2*. On the contrary, if the depends list is [task2, task1], then results[0] will contain the result of *task2* and results[1] the result of *task1*.

[source, xml]
----
<depends>
        <task ref="task1"/>
        <task ref="task2"/>
</depends>
----

For nearly all script languages, the *results* variable contains a list of link:../javadoc/org/ow2/proactive/scheduler/common/task/TaskResult.html[TaskResult java object].
In order to access the result value, the value() method of this object must be called.
Example for Python/Jython:
[source, python]
----
print results[0].value()
----

==== Assigning metadata to task result

Result metadata can contain additional information associated with the result. In order to store metadata information, use the following syntax, if task2 depends on task1:

[source, groovy]
----
// task1
result = "task1";
resultMetadata.put("mymetadata", "myvalue")
----

[source, groovy]
----
// task2
println(results[0].getMetadata());
----

It is up to the user code to decide the metadata semantics, but some specific metadata can have a meaning when downloading or previewing results from the *Scheduler portal*:

- *file.name:* the name of the file, including the extension, which will be used when storing the result in binary format.
+
[source, groovy]
----
// fileNameTask
file = new File("balloon13.png")
result = file.getBytes()
resultMetadata.put("file.name","balloon13.png")
----

- *file.extension:* the extension, which will be appended to the automatically generated name, when storing the result in binary format
+
[source, groovy]
----
// fileExtensionTask
file = new File("balloon13.png")
result = file.getBytes()
resultMetadata.put("file.extension",".png")
----

- *content.type:* the display format, which will be used when previewing the file in the browser. Open the following https://www.iana.org/assignments/media-types/media-types.xhtml[link] for the complete list of mime-types.
+
[source, groovy]
----
// contentTypeTask
file = new File("balloon13.png")
result = file.getBytes()
resultMetadata.put("content.type","image/png")
----

A Task result can be added to the list of results of a Job, see section <<_result_list>> below.

=== Job Results

Job Results are composed of two elements: *Result List* and *Result Map*.
Each task can contribute as for *Result List* as for *Result Map*.
Once the job is finished, you can download/visualize Job Results from the Scheduler portal:

image::scheduler-result-map.png[align=center]

In the figure above, the label in *Result List* corresponds to the task name that generated the value.

[[_result_list]]
==== Result List

Each task has its own result (see section <<_task_result>>).
However, some task results can be marked as *Task Result Added to Job Result*.
In that case, this task result will be added to the *Result List*.
You can mark your task in the Studio:

image::precious-result.png[align=center]

In the Job xml schema it is available as `preciousResult`:

``` {.xml}
<task name="Init_Task" preciousResult="true" >
```

==== Result Map

In addition to the *Results List*,
a Job can also store some results into a dedicated key-value map,
which is called *Result Map*. Every task can contribute to this *Result Map*.
It is a write-only map, in such a way that a task cannot see
what other tasks already wrote to the result map.
When several tasks write the same key to the result map,
the last write always takes precedence. This map contains String as a key,
and https://docs.oracle.com/javase/8/docs/api/java/io/Serializable.html[Serializable ^] as value.

Consider the following groovy example.

`Task 1` writes to *Result Map*:
[source, groovy]
----
resultMap.put("filename", "results.txt")
resultMap.put("latestError", "no error")
----

`Task 2` writes to *Result Map*:
[source, groovy]
----
resultMap.put("latestError", "wrong user id")
----

Once the job is finished, *Result Map* would contain:
[source, groovy]
----
"filename" -> "results.txt"
"latestError" -> "wrong user id"
----


=== Control Flow Scripts

To perform a control flow action such as if, replicate or loop, a
*Control Flow Script* is executed on the ProActive node. This script
takes the result of the task as input; meaning a Java object if it was a
Java or Script task, or nothing if it was a native task.

The script is executed on the ProActive node, just after the task's
executable. If the executable is a Java Executable and returns a result,
the variable `result` will be set in the script's environment so that
dynamic decisions can be taken with the task's result as input. Native
Java objects can be used in a Groovy script.

.Decide whether to keep looping or not based on the task's result:
[source,groovy]
----
loop = result
----

Similarly to how parameters are passed through the *result* variable to
the script, the script needs to define variables specific to each action
to determine what action the script will lead to.

-   A *replicate* control flow action needs to define how many parallel
    runs will be executed, by defining the variable `runs`:

[source,groovy]
----
// assuming result is a java.lang.Integer
runs = result % 4 + 1
----

The assigned value needs be a strictly positive integer.

-   An *if* control flow action needs to determine whether the if or the
    else branch is selected, it does this by defining the boolean
    variable `branch`:

[source,groovy]
----
// assuming result is a java.lang.Integer
if (result % 2) {
  branch = "if"
} else {
  branch = "else"
}
----

The assigned value needs to be the string value _if_ or _else_.

-   The *loop* control flow action requires setting the `loop`, which
    will determine whether looping to the statically defined target is
    performed, or if the normal flow is executed as would a continue
    instruction do in a programming language:

[source,groovy]
----
loop = result as Boolean
----

The assigned value needs to be a boolean.

Failure to set the required variables or to provide a valid
control flow script will not be treated gracefully and will result in
the failure of the task.

=== Loop and Replicate awareness

When Control Flow actions such as *replicate* or *loop* are performed,
some tasks are replicated. To be able to identify replicated tasks
uniquely, each replicated task has an *iteration index*, *replication
index*, and a *tag*. In addition to help to identify uniquely, these tags are
useful to filter tasks by iterations for example.


==== Task name

First, those indexes are reflected inside the names of the tasks
themselves. Indeed, task names must be unique inside a job. The indexes
are added to the original task name as a suffix, separated by a special
character.

-   If a task named _T_ is replicated after a *loop* action, the newly
    created tasks will be named _T#1_, _T#2_, etc. The number
    following the _#_ separator character represents the *iteration
    index*.

-   The same scheme is used upon *replicate* actions: newly created
    tasks are named _T*1_, _T*2_, and so on. The number following the
    $$*$$ separator represents the *replication index*.|

-   When combining both of the above, the resulting task names are of
    the form: _T#1*1_, _T#2*4_, etc., in that precise order.


==== Task tag

Tags are assigned automatically by the scheduler when a task is created by
replication from another task. They are designed to reflect the task that
initiated the replication for the first time, the type of replication (loop
or replicate) and the iteration index or replication indexes. So the tag is
formed like this: *(LOOP|REPLICATE)-Name_of_the_initiator-index*.

-   If the task _T1_ initiates a loop that contains the tasks _T2_ and _T3_,
    then the tasks _T2#1_ and _T3#1_ will have the tag *LOOP-T1-1*. The tasks
    _T2#2_ and _T3#2_ will have the tag *LOOP-T1-3*.

-   If the loop is a cron loop, the index is replaced by the resolved time of
    the initiated looping. For example, in a cron loop that was initiated the
    21/12/2015 at 14h00, the task _T1#1_ will have the tag *LOOP-T1#1-21_12_15_14_00*.

-   If the task _T1_ replicates a block that contains the tasks _T2_ and _T3_,
    then the tasks _T2*1_ and _T3*1_ will have the tag *REPLICATE-T1-1*. The
    tasks _T2*2_ and _T3*2_ will have the tag *REPLICATE-T1-2*.

-   If the task _T1#1_, inside a loop, replicates tasks, the new tasks will have
    the tags *REPLICATE-T1#1-1*, *REPLICATE-T1#1-2*, etc...

-   If the replicated task _T1*1_ initiates a loop inside a replicate, the new
    created tasks will have the tags *LOOP-T1*1-1*, *LOOP-T1*1-2*, etc...


==== Task definition

Those indexes are also available as <<_workflow_variables,workflow variables>>. They can be
obtained using the variable names:

* PA_TASK_REPLICATION
* PA_TASK_ITERATION

Here is how to access those variables:

-   *Native Executable arguments:*

[source, xml]
----
<staticCommand value="/path/to/bin.sh">
  <arguments>
    <argument value="/some/path/${PA_TASK_ITERATION}/${PA_TASK_REPLICATION}.dat" />
----

-   *Dataspace input and output:*

[source, xml]
----
<task name="t1" retries="2">
  <inputFiles>
    <files includes="foo_${PA_TASK_ITERATION}_${PA_TASK_REPLICATION}.dat" accessMode="transferFromInputSpace"/>
  </inputFiles><outputFiles>
    <files includes="bar_${PA_TASK_ITERATION}_${PA_TASK_REPLICATION}.res" accessMode="transferToOutputSpace"/>
----

NOTE: Scripts affected by the variable substitutions are: Pre, Post, Control Flow.
*No substitution will occur in selection scripts or clean scripts.*



==== Task executable

The iteration and replication indexes are available inside the
executables launched by tasks.

In script tasks, the indexes are exported through the following <<_workflow_variables,workflow variables>>:
 `PA_TASK_ITERATION` and `PA_TASK_REPLICATION`.

[source,groovy]
----
int it  = variables.get("PA_TASK_ITERATION")
int rep = variables.get("PA_TASK_REPLICATION")
----

In a similar fashion, environment variables are set when launching a
native executable: `PAS_TASK_ITERATION` and `PAS_TASK_REPLICATION`:

``` {.sh}
#!/bin/sh
myApp.sh /path/to/file/${variables_PAS_TASK_ITERATION}.dat

```

=== Example: Embarrassingly Parallel problem

An https://en.wikipedia.org/wiki/Embarrassingly_parallel[Embarrassingly Parallel problem^] is a problem that is easy
to split into smaller independent tasks. With ProActive Scheduler you can tackle this type of problem with the
<<_replicate>> construct.

TIP: Familiar with https://en.wikipedia.org/wiki/MapReduce[MapReduce^]? Well, a workflow using replication
uses similar concepts.

The https://try.activeeon.com/tutorials/adv.html[Advanced workflows^] is an example of an embarrassingly parallel
problem where the computation is easily distributed across ProActive Nodes.

[[_mpi_application]]
=== Example: MPI application

https://en.wikipedia.org/wiki/Message_Passing_Interface[MPI^] is often used in the area of parallel computing.
The Scheduler integrates with MPI with the concept of <<_multi_node_task,multi node tasks>>.
 This particular task will acquire several nodes and will expose these nodes to the MPI environment.

Applications built with MPI are often executed using the https://linux.die.net/man/1/mpirun[mpirun^] command.
It accepts several parameters to
choose how many CPUs and how many machines will be used. One particular parameter is the machine file that is
built by the Scheduler when using *multi node tasks*.
Here is how an MPI application invocation would look like when executed with the Scheduler:

    mpirun -hostfile $variables_PA_NODESFILE myApplication

The <<_workflow_variables,variable>> `$variables_PA_NODESFILE` contains the path to a machine file created by the Scheduler that will be similar to:

    compute-host
    compute-host
    another-host

Meaning that `myApplication` will use 2 CPUs on `compute-host` and 1 CPU on `another-host`.
You can also use `$variables_PA_NODESNUMBER` to retrieve the number of acquired nodes.

You can find an example of a native task in this
link:examples/mpi_task.xml[XML workflow^] or you can also build one yourself using the
*Workflow Studio*.

To achieve the best performance for MPI applications, nodes can be selected taking into account their *network topology*. One might want to select nodes that are as
close to each other as possible to obtain better network performance or nodes on different hosts to split the I/O load.
Refer to <<_topology_types>> for more details.

== Workflow Execution Control

*ProActive Scheduler* supports portable script execution through the *JSR-223* Java
Scripting capabilities. Scripts can be written in any language supported by the underlying
Java Runtime Environment.

They are used in the ProActive Scheduler to:

* Execute some simple *pre*, *post* and *cleaning* processing (pre scripts, post scripts and cleaning scripts)
* Select among available resources the node that *suits the execution* (selection scripts).

[[_selection]]
=== Selection of ProActive Nodes

A <<_glossary_selection_script, selection script>> provides an ability for the Scheduler to execute tasks on particular ProActive nodes.
E.g. you can specify that a task must be executed on a Unix/Linux system.

A <<_glossary_selection_script, selection script>> is always executed before the task itself on any candidate node:
the execution of a <<_glossary_selection_script, selection script>> must set the boolean variable `selected`,
that indicates if the candidate node is suitable for the execution of the associated task.

A Java helper *org.ow2.proactive.scripting.helper.selection.SelectionUtils* is provided for allowing
user to simply make some kind of selections. Some script samples are available in
`PROACTIVE_HOME/samples/scripts/selection`.

The following example selects only nodes running on Windows:

[source, javascript]
----
importClass(org.ow2.proactive.scripting.helper.selection.SelectionUtils);

/* Check if OS name is Windows */
if (SelectionUtils.checkOSName("windows")) {
    selected = true;
} else {
    selected = false;
}
----

You can use variables inside the <<_glossary_selection_script, selection script>>, these variables must be visible within the task
context, i.e., declared on job scope, on task scope, or result variable from a previous task. In the last
case, it is mandatory that the task which declares the inherited variable precedes the task using the variable. Below
is an example job in XML format which uses a task variable to select Unix/Linux as operating system. In this example,
variable *operating_system* (task scope) resolves to variable *operating_system_workflow* (job scope).

[source, xml]
----
<?xml version="1.0" encoding="UTF-8"?>
<job
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xmlns="urn:proactive:jobdescriptor:3.10"
     xsi:schemaLocation="urn:proactive:jobdescriptor:3.10 https://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.10/schedulerjob.xsd"
    name="variable solving"
    priority="normal"
    onTaskError="continueJobExecution"
     maxNumberOfExecution="2"
>
  <variables>
    <variable name="operating_system_workflow" value="linux" model=""/>
  </variables>
  <taskFlow>
    <task name="Groovy_Task0">
      <description>
        <![CDATA[ The simplest task, ran by a groovy engine. ]]>
      </description>
      <variables>
        <variable name="operating_system" value="$operating_system_workflow" inherited="false" />
      </variables>
      <scriptExecutable>
        <script>
          <code language="groovy">
            <![CDATA[
                import org.ow2.proactive.scripting.helper.selection.SelectionUtils
                selected = SelectionUtils.checkOSName(variables.get("operating_system"))
            ]]>
          </code>
        </script>
      </scriptExecutable>
    </task>
  </taskFlow>
</job>
----

=== Fork environment

A fork environment is a new forked Java Virtual Machine (JVM) which is started exclusively to execute a task. For example, this task may need to use some third-party libraries, so it can be executed properly. In this example, the list of path elements to be added when starting a new JVM will be specified inside the `Additional Classpath` field.
Starting a new JVM means that the task inside it will run in a dedicated, configurable environment.

==== Fork environment modes
The fork environment can be activated through one of these four executions modes:

- Standard forked mode,
- Fork mode with customized configuration,
-  link:../admin/AdminTutorials.html#_run_as_me[Run as me] mode,
- Fork mode with docker.

image::fork-environment.png[align=center]


By default, all workflow tasks are executed in a standard fork mode, that is, executed in a forked JVM separated from the ProActive Node's JVM.
This behavior can be controlled *globally* at the ProActive server level by modifying the global setting `pa.scheduler.task.fork` in the <<../admin/ProActiveAdminGuide.adoc#_general_configuration,scheduler configuration file>> and also *locally* at the task level via the optional checkbox property *Fork*.

- In case the server is configured in non-fork mode (i.e. `pa.scheduler.task.fork` = `false`), the checkbox property *Fork* is unchecked and uneditable and all the fields under *Fork Environment* are uneditable.

- In case the server is configured in a fork mode (i.e. `pa.scheduler.task.fork` = `true`), the checkbox property *Fork* is checked and uneditable and all the fields under *Fork Environment* are editable.

- In case the global setting is not set (i.e. comment out the related configuration through `#pa.scheduler.task.fork` = `true`), each task can specify its execution mode through the checkbox property *Fork*. If the checkbox property *Fork* is unchecked, then all the other fields under *Fork Environment* are disabled.

==== Fork environment customization

The fork execution environment mechanism can be customized by writing a <<_glossary_fork_environment_script,fork environment script>>.
This script contains a specific <<_glossary_script_bindings,script binding>> called `forkEnvironment` containing a link:../javadoc/org/ow2/proactive/scheduler/common/task/ForkEnvironment.html[ForkEnvironment java object]
giving access to various configuration settings.

For example, the following fork environment groovy script can be written to change the working directory of the task, and the path to the java executable:

```groovy
forkEnvironment.setWorkingDir("/data/folder")
forkEnvironment.setJavaHome("/usr/java/default")
```

==== Docker fork execution environment
A Docker fork execution environment is a specific usage of the fork environment mechanism.
In that case, the ProActive Node's JVM starts a docker container which will run the forked JVM described above.
This forked JVM can be customized by the JVM settings and by the tool-set and isolation provided by Docker containers.

TIP: If your task needs to install new software or updates software, then run it inside a Docker container.
That way, other tasks will not be affected by changes, because Docker containers provide isolation so that
the host machine's software stays the same.

===== The simplest way to use a Docker fork execution environment
From the +++<a class="studioUrl" href="/studio" target="_blank">Studio Portal</a>+++, when editing a workflow task, open the *Fork Environment* section, and select `Docker` in the *Fork Execution Environment* Dropdown.
A sample Docker environment script will appear.

These settings ensure, that the current task is executed inside a Docker container, or fail if Docker is
 not installed or the user has no permission to run Docker containers.

TIP: If the executing Node has no Docker installed, the task will fail. A <<_selection,selection script>> can ensure
that tasks are executed only on Nodes which have Docker installed.

===== Docker fork environment script
The default Docker fork environment script contains the following groovy code:
[source, groovy]
----
// This script creates a docker fork environment using java as docker image

// If used on windows:
//  - currently, only linux containers are supported
//  - make sure the drives containing the scheduler installation and TEMP folders are shared with docker containers
//  - the container used must have java installed by default in the /usr folder. Change the value of the java home parameter to use a different installation path
// On linux, the java installation used by the ProActive Node will be also used inside the container

// Prepare Docker parameters
import org.ow2.proactive.utils.OperatingSystem;
import org.ow2.proactive.utils.OperatingSystemFamily;

containerName = "java"
cmd = []
cmd.add("docker")
cmd.add("run")
cmd.add("--rm")
cmd.add("--env")
cmd.add("HOME=/tmp")

String osName = System.getProperty("os.name");
println "Operating system : " + osName;
OperatingSystem operatingSystem = OperatingSystem.resolveOrError(osName);
OperatingSystemFamily family = operatingSystem.getFamily();

switch (family) {
    case OperatingSystemFamily.WINDOWS:
    	isWindows = true;
    	break;
    default:
        isWindows = false;
}
forkEnvironment.setDockerWindowsToLinux(isWindows)

// Prepare ProActive home volume
paHomeHost = variables.get("PA_SCHEDULER_HOME")
paHomeContainer = (isWindows ? forkEnvironment.convertToLinuxPath(variables.get("PA_SCHEDULER_HOME")) : variables.get("PA_SCHEDULER_HOME"))
cmd.add("-v")
cmd.add(paHomeHost + ":" + paHomeContainer)
// Prepare working directory (For Dataspaces and serialized task file)
workspaceHost = localspace
workspaceContainer = (isWindows ? forkEnvironment.convertToLinuxPath(workspaceHost) : workspaceHost)
cmd.add("-v")
cmd.add(workspaceHost + ":" + workspaceContainer)

cachespaceHost = cachespace
cachespaceContainer = (isWindows ? forkEnvironment.convertToLinuxPath(cachespaceHost) : cachespaceHost)
cmd.add("-v")
cmd.add(cachespaceHost + ":" + cachespaceContainer)

if (!isWindows) {
     // when not on windows, mount and use the current JRE
    currentJavaHome = System.getProperty("java.home")
	forkEnvironment.setJavaHome(currentJavaHome)
    cmd.add("-v")
    cmd.add(currentJavaHome + ":" + currentJavaHome)
}

// Prepare container working directory
cmd.add("-w")
cmd.add(workspaceContainer)

if (isWindows) {
    // linux on windows does not allow sharing identities (such as AD identities)
} else {
    sigar = new org.hyperic.sigar.Sigar()
    try {
        pid = sigar.getPid()
        creds = sigar.getProcCred(pid)
        uid = creds.getUid()
        gid = creds.getGid()
        cmd.add("--user=" + uid + ":" + gid)
    } catch (Exception e) {
        println "Cannot retrieve user or group id : " + e.getMessage()
    } finally {
        sigar.close()
    }
}
cmd.add(containerName)

forkEnvironment.setPreJavaCommand(cmd)

// Show the generated command
println "DOCKER COMMAND : " + forkEnvironment.getPreJavaCommand()
----
This script exports a variable composed of a list of command + arguments via the forkEnvironment.getPreJavaCommand function, which is picked up by the Node executing the Task.
This variable is supposed to be a Docker run command inside a string.
This string will be split by space and added in front of the fork execution command. As an example:
----
/usr/bin/java -cp [Classpath] [ExecutedClass]
----
And the Docker run command is:
----
docker run java
----
Then both will be combined to:
----
 docker run java /usr/bin/java -cp [Classpath] [ExecutedClass]
----

The combined command will execute a JVM inside a docker container.
Internally the command is split into docker, run, java, /usr/bin/java, -cp, [Classpath], [ExecutedClass].
 That is important to know because the fork execution command is split by spaces.
  That means, that paths can’t contain spaces. The Docker container mounts the ProActive home and a
   folder in the temp directory of the operating system. Those cannot contain spaces, because if they
    do then the fork execution command will be split wrong and fail.


[[_pre_post_clean]]
=== Pre, Post & Clean Scripts

Another functionality is the possibility to define pre and post scripts. For a given task (Java, Script or Native task),
it is possible to launch a script before and after its execution. This possibility can be useful to copy files
to a node, or clean a directory before or after task execution, for example.

This is a way to separate from business code the preparation of execution environment and its cleaning. A good example
is a script that removes files from a specific directory once the task is finished.

.Clean script example
[source, groovy]
----
Files.deleteIfExists(new File("/tmp/working_dir/").toPath())
----


==== File transfer

===== Input/Output Data in Shared Directory

The easiest way to use your data on computing machines is to set up a *shared directory* available on all Compute Hosts. For
Linux it's typically an NFS directory, for Windows it could be an SMB network share. Then, in tasks you can manipulate
files seamlessly across ProActive Nodes.

[source, java]
----
File inputData = new File("/data/username/inputfile");
----

This approach has some limitations though:

* The path to the shared folder should be *identical* on all Compute Hosts
* It can be difficult to use with *heterogeneous resources*, e.g. Linux and Windows hosts

==== Save script

===== Save the pre-script in a file and skip its execution

Instead of executing the pre-script, we also provide to save the pre-script in a file and skip the execution. To do so, a Generic Information is required for the desired task, with the key
"PRE_SCRIPT_AS_FILE", and the path of the file that you want to save your pre-script as its value. The path should contain a file name. It can be an absolute path, then the file will be stored in this absolute path. It can
 also be a relative path, then the file will be stored in the link:../user/ProActiveUserGuide.html#_local_space[Local Space]. If you don't give a specific extension in the path, the extension will be automatically assigned to the corresponding one of the language selected for this pre-script.


=== Run computation with your system account

It is possible to start a task under the job owner if the system is configured for that purpose.
There are 2 possible ways to run a task under user account
(in any case, the administrator should have
link:../admin/ProActiveAdminGuide.html#_run_as_me[set computing hosts] to authorize
one of the 2 methods):

* Using your *scheduling login and password*: if computing hosts are configured and user is authorized to run a process under his login and password.
* Using an *SSH key* provided by the administrator: if computing hosts are configured, the administrator should have given user an SSH key.

User must first create a credential containing this key:

----
$ PROACTIVE_HOME/tools/proactive-create-cred -F config/authentication/keys/pub.key -l username -p userpwd -k path/to/private/sshkey -o myCredentials.cred
----

This command will create a new credentials with *username* as login, *userpwd* as password, using Scheduler public key at
`config/authentication/keys/pub.key`
for credentials encryption and using the private SSH key at
`path/to/private/sshkey`
provided by administrator. The new credential will be stored in *myCredentials.cred*

Once created, user must connect the Scheduler using this credential. Then, in order to execute your task under your account
set *runAsMe=true* in the task.

TIP: You can now use <<_third_party_credentials,third party credentials>> to store the SSH key with the special entry named *SSH_PRIVATE_KEY*.

[[_multi_node_task]]
=== Reserve more than one node for a task

To create a <<_mpi_application,multi-nodes>> task often used for MPI applications you need to add a *parallel environment*
to the task. Parallel environment describes how many nodes are needed for a task as well as where these nodes should be
located. For example if you'd like to run 4 processes in parallel it a scope of one task you should specify it in your task

[source, xml]
----
<parallel numberOfNodes="4"/>
----

NOTE: For instance if 4 nodes are running on a given note (often because the host has 4 cores), then
a multi-nodes task that requires 4 nodes might select the 4 workers on this host.

==== Defining a Topology for Multi-Nodes Tasks

In addition to the number of ProActive Nodes you can specify the *nodes network topology*, e.g
the set of nodes within some latency threshold, nodes on the same host and many more.


Here is the list of topologies we support:

* *Arbitrary* topology does not imply any restrictions on nodes location
* *Best proximity* - the set of closest nodes among those which are not executing other tasks.
* *Threshold proximity* - the set of nodes within a threshold proximity (in microseconds).
* *Single Host* - the set of nodes on a single host.
* *Single Host Exclusive* - the set of nodes of a single host exclusively. The host with selected nodes will be reserved for the user.
* *Multiple Hosts Exclusive* - the set of nodes filled in multiple hosts. Hosts with selected nodes will be reserved for the user.
* *Different Hosts Exclusive* - the set of nodes each from a different host. All hosts with selected nodes will be reserved for the user.

=== Handling failures

It’s possible to have errors when your Job is executed. *ProActive Scheduler* provides several mechanisms to deal with exceptional situations in your Jobs.
If a Task contains errors during Job execution, the *ProActive Scheduler* automatically restarts this Task. The number of automatic restarts is defined by the Workflow owner by assigning an integer value to the counter *Number of Automatic Restarts*.
The user also defines *Where he wants that the scheduler restarts In-Error tasks*, i.e., on the same ProActive Node or on another ProActive Node.

If automatic restarts does not fix errors, the Scheduler applies one of the following Task error management policies, i.e., the one defined by the user during Workflow creation:

* *Ignore error and continue Job execution* - each *In-Error* Task inside the Job transits to *Faulty* and its successor Tasks are executed.

* *Only suspend dependencies of In-Error Tasks* - successor Tasks of each *In-Error* Task are *Pending* until errors are fixed. The Job is in *In-Error* state.
                                               The user can restart *In-Error* Tasks as many times as he wishes.


* *Pause Job execution (running Tasks can terminate)* - successor Tasks of each *In-Error* Task are paused until errors are fixed. The Job is paused.
                                                     The user can restart *In-Error* Tasks as many times as he wishes.

* *Kill Job (running Tasks are killed)* - The Job is killed with all Tasks.


==== Maximum execution time for a task

A `timeout` (also known as `walltime`) can be set at the task's level to stop a task's execution when the timeout is reached.
The general format of the walltime attribute is `[hh:mm:ss]`, where h is hour, m is minute and s is second.
The format still allows for more flexibility. We can define the walltime simply as `5` which corresponds to
5 seconds, `10` is 10 seconds, `4:10` is 4 minutes and 10 seconds, and so on.

The walltime mechanism is started
just before a task is launched. If a task does finish before its walltime, the mechanism is canceled. Otherwise,
the task is terminated. Note that the tasks are terminated without any prior notice.

=== Cron Workflows
The *ProActive Scheduler* allows to schedule <<_glossary_workflow,*Workflows*>> with the <<_glossary_job_planner,*Job Planner*>>.
Find more information in the link:../JobPlanner/JobPlannerUserGuide.html[*Job Planner User Guide*].


=== Cron Tasks
*ProActive Scheduler* supports the execution of time-based tasks or cron tasks. The users can assign a
cron expression to the `loop` variable of a *Loop* in a ProActive Job. All tasks which belong
that Loop will be executed iteratively and indefinitely. The start time of the next iteration
is the next point of time specified by the cron expression.


==== Cron Expression Syntax
The syntax of the follows the UNIX crontab pattern, a string consists of five space-separated segments.
 Please refer http://www.sauronsoftware.it/projects/cron4j/manual.php#p02[cron4j documentation] for further details.

==== Setting up Cron Tasks
Setting up a cron task requires two steps:

* Define a *Loop* with the desired cron tasks
* Assign a cron expression as the `loop` variable value

Example that prints _Hello_ every 10 minutes:
[source, xml]
----
<job name=”cron_job”>
     <genericInformation>
        <info name="START_AT" value="2014-01-01T00:00:00+01:00"/>
    </genericInformation>
    <task name=”cron_task”>
        <scriptExecutable>
            <script>
                <code language="javascript">
                    print("Hello");
                </code>
            </script>
        </scriptExecutable>
        <controlFlow>
            <loop target=”cron_task”>
                <script>
                    loop = “10 * * * *”
                </script>
            <loop>
        </controlFlow>
    </task>
</job>
----

You can find a complete example running a simple task every minutes in this link:examples/cron_task.xml[XML workflow^].

==== Notes

* The execution of the first iteration occurs immediately and does not depend on the cron expression specified.
 However the user can specify a start time for the first iteration using `START_AT` <<_generic_information,generic information>>.
 Its value should be https://en.wikipedia.org/wiki/ISO_8601[ISO 8601^] compliant.

* Each iteration yields one or more task results and the user can query the job state and task states to
retrieve information of each iteration.

* It is assumed that execution time of each iteration is less that time gap specified by the cron expression.
 If the execution time of an iteration is longer, the execution of the next iteration will occur at next point
  of time with respect to the current time. For instance it is possible to observe lesser number of iteration
   executed within a certain time period than number of expected iterations, if some iterations had take longer finish time.

* If the execution of the task defining the loop (where the <controlFlow> block is defined) fails,
 the cron execution is terminated.

* ProActive Scheduler executes any cron task indefinitely. Therefore the state of ProActive Job will remain
 `RUNNING` unless the cron task execution terminates either by the user (for instance by killing the job
  or the task) or due an error in the task execution.

=== Remote Visualization

Using the Scheduler Web Interface, it is possible to access the display of the ProActive Node running a given task.
First remote visualization must be activated via the
link:../admin/ProActiveAdminGuide.html#_rest_api_properties[Scheduler configuration files] (set *novnc.enabled* to true).

NOTE: Remote visualization works via VNC where the REST API will connect to the node running the task, i.e a graphical
application. The VNC output will be forwarded to the your browser and you will be able to interact with the
application.

The task that you want to visualize must output a special string using the following format:
*PA_REMOTE_CONNECTION;JOB_ID;TASK_ID;vnc;HOSTNAME:PORT* where *JOB_ID* must be the current _job id_, *TASK_ID* the current _task id_
and *HOSTNAME:PORT* the hostname and port where the VNC server runs.

It is the task's responsibility to print the string.
Here is a link:examples/remote_visualization_script.sh[sample script^] that starts a Xvnc server and runs
 a graphical application.
It can be used in a native task for instance.

In the Scheduler Web Interface, select the running job and use the _Preview_ tab to enable remote visualization.

TIP: Since it runs a graphical application, the task will never exit and run forever. The common use case is that
you want to check manually some results via the graphical application and then exit the application.
The task will then terminate normally.

=== Troubleshoot a Workflow Execution

When a task has *IN_ERROR* status, a right click on it allows the user to select _Mark as finished and resume_.
This will set the task status as *FINISHED* and then resume job execution: this task won't be executed again, subsequent tasks will execute as if the task executed correctly.
This allows the user to manually perform actions to the *IN_ERROR* task, without cancelling the whole job execution.


If the task has not *IN_ERROR* status, the _Mark as finished and resume_ option will be in grey, meaning that the action is disabled.

=== Get Notifications on Job Events

Add a "NOTIFICATION_EVENTS" Generic information in the workflow level, to list events on which a user wants to be notified. List is comma-separated and should be taken from(events are not case sensitive):

* *Job change priority (or JOB_CHANGE_PRIORITY)*
* *Job In-Error (or JOB_IN_ERROR)*
* *Job paused (or JOB_PAUSED)*
* *Job pending to finished (or JOB_PENDING_TO_FINISHED)*
* *Job pending to running (or JOB_PENDING_TO_RUNNING)*
* *Job restarted from error (or JOB_RESTARTED_FROM_ERROR)*
* *Job resumed (or JOB_RESUMED)*
* *Job running to finished (or JOB_RUNNING_TO_FINISHED)*
* *Job submitted (or JOB_SUBMITTED)*
* *Job running to finished with errors (or JOB_RUNNING_TO_FINISHED_WITH_ERRORS)*
* *Job aborted (or JOB_ABORTED)*


Scheduler can send email to the users when one of the above events is received.

If a user wants to be notified by all these events, the "NOTIFICATION_EVENTS" Generic information should have "All" (not case sensitive) as its value.

Notifications will only be sent for jobs whose generic information (workflow level) contains user's email address(es) under the "EMAIL" key, if multiple email addresses need to be used, they should be seperated by comma. Example:

[source, xml]
----
<genericInformation>
    <info name="EMAIL" value="user0@example.com, user1@example.com"/>
    <info name="NOTIFICATION_EVENTS" value="Job paused, Job resumed"/>
</genericInformation>
----

To enable this functionality, the configuration need to be done following the steps introduced in
link:../admin/ProActiveAdminGuide.html#_get_notifications[Get Notification on Job Events Configuration].

=== Chaining Jobs

In *ProActive Studio*, the `SubmitJobNoWait` and `SubmitJobAndWait` templates under the *Controls* menu allow you to submit a workflow from another workflow using the <<_scheduler_api,*schedulerapi*>> binding.

These templates accept the single parameter:

 * `called_workflow`: a <<_proactive_catalog_object_storage_and_versioning,ProActive Catalog>> path referencing the workflow to submit (e.g. _basic-examples/Native_Task_)

By default, these templates do not pass any parameter to the submitted workflow (using only default values provided by the workflow).

It is possible to modify this behavior by changing the `SubmitJobNoWait` or `SubmitJobAndWait` implementation.

For example, the following line can be replaced:

[source,groovy]
----
workflow_variables = Collections.EMPTY_MAP
----
by
[source,groovy]
----
workflow_variables = [firstName:'John', lastName:'Doe']
----
To provide the _firstName_ and _lastName_ variables parameters to the submitted workflows.

The `SubmitJobNoWait` or `SubmitJobAndWait` templates behavior is different in the sense that the latter will wait until the submitted workflow terminates.

=== Control and Validation

In order to better control your workflows, two ProActive Studio templates *Web Validation* and *Email Validation* are provided under the *Manuals* menu. These templates aim at validating part of your workflows manually. The tasks after the validation template will only be executed
once you validate it. You can put your description of the validation under the *content* variable in *Web Validation* template, and under *message* variable in *Email Validation* template. Three options are provided, the *Yes* option indicates that you want
to validate the workflow and continue the execution of the rest tasks; the *Maybe* option means that you do not know what to do for the moment; the *No* option denotes that you do not want to validate the workflow, and the remaining of the workflow will be paused.

In order to validate your workflow using *Web Validation*, you need to go to the *ProActive Notification & Validation* portal, the workflow will be validated by clicking on one of the three buttons. By using *Email Validation*, you will receive an email with three links, the workflow can be validated by clicking on one of the links.

== Data Spaces

If a shared folder or file system is not an option in your environment, the ProActive Scheduler provides a convenient way to transfer files between server and tasks.

This mechanism is called *ProActive Data Spaces*.

Data Spaces come into two categories:

* *Server Data Spaces*: Global and User Spaces belong to this category. It represents data spaces located on the server side.
* *Node Data Spaces*: Local and Cache Spaces belong to this category. It represents data spaces located on the Node or during a Task execution.

=== Global and User Spaces

Server Data Spaces have two types of storage on the host where the ProActive server is running:

* A *Global Space* where anyone can read/write files
* An *User Space* which is a personal user data storage

By default, these spaces are linked to folders in the *data* directory of the ProActive Scheduler host:

 * `PROACTIVE_HOME/data/defaultglobal`
 * `PROACTIVE_HOME/data/defaultuser`

But it can be changed in `PROACTIVE_HOME/config/scheduler/settings.ini`.

=== Local Space

The *Local Space* is a Node Data Space created dynamically when a Task is executed.

The *Local Space* allows to:

* Transfer files from one of the Server Spaces (Global or User) to the task execution context, before the task starts its execution.
* Transfer files from the task execution context to one of the Server Spaces (Global or User) at the end of the task execution.

These two types of transfers must be declared in the Task definition in order to occur (transfer is not implicit).
You need to define which files have to be transferred from a data space to computing nodes by using *input files* and reciprocally from computing nodes to a data space by using *output files*:

[source, xml]
----
<task name="task1">
    ...
    <inputFiles>
        <files includes="tata" accessMode="transferFromGlobalSpace"/>
    </inputFiles>
    <outputFiles>
        <files includes="titi*" accessMode="transferToGlobalSpace"/>
    </outputFiles>
    ...
</task>
----

Upon the execution of the previous example, ProActive Scheduler automatically transfers all files to a ProActive Node where the task will be executed. The files are put in a special place called *Local Space* on the ProActive Node. It corresponds to the working directory of a task when the task is in fork mode (default).
From a task point of view, files can be accessed normally like shown below:

[source, java]
----
File inputFile = new File("tata")
----

Then, based on the previous task definition, all the files whose the name starts with _titi_ (e.g titi, titi2, etc.) produced by _task1_ will be transferred back automatically to Global Space by the Scheduler once the task is finished.

Files can be also transferred from/to User Space by specifying `transferFromUserSpace`/`transferToUserSpace`.

Before running your jobs you should first *upload* your files into either Global or User Space. To do it you can export folders linked to
these spaces by one of the standard protocols like *FTP*, *NFS*, or use available web interfaces like
https://pydio.com/[Pydio^].

It is possible to use wildcards in transfer directives, such as:

[source, xml]
----
<task name="task1">
    ...
    <inputFiles>
        <files includes="**/tata" accessMode="transferFromGlobalSpace"/>
    </inputFiles>
    <outputFiles>
        <files includes="*" accessMode="transferToGlobalSpace"/>
    </outputFiles>
    ...
</task>
----

More information of pattern syntax can be found in the https://docs.oracle.com/javase/7/docs/api/java/nio/file/FileSystem.html#getPathMatcher(java.lang.String)[FileSystem class JDK documentation].


=== Cache Space

In addition to transferring to the Task *Local Space*, it is also possible to transfer files to the Node host *Cache Space*.

From the Node host point of view, the Cache Space is *unique* and shared for all tasks and all ProActive Nodes deployed on the host.

Transfers to the cache are *not concurrent*, only a single task can transfer to the cache at the same time. I.e if multiple tasks are run in parallel on the same hosts and they all transfer to the cache, these transfers will be executed sequentially.

If a file declared for the transfer is newer than the existing version in the cache, the file will be updated.

In order to transfer files to the cache, simply use the cache transfer directives inside your job:

[source, xml]
----
<task name="task1">
    ...
    <inputFiles>
        <files includes="tata" accessMode="cacheFromGlobalSpace"/>
        <files includes="toto" accessMode="cacheFromUserSpace"/>
    </inputFiles>
    ...
</task>
----

The files will not be transferred to the Local Space of the task, so it will not be possible to access these files from the current directory.

In order to access these files, use the *cachespace* variable which contains the location of the cache, for example in groovy:

[source, groovy]
----
inputFile = new File(cachespace, "tata")
----

There are no transfer directives to transfer output files *from* the cache. Output files transfers are only possible from the *Local Space*.

Files in the cache space are *automatically deleted* after a given period. The default invalidation period is two weeks, which means that files older than two weeks will be automatically deleted.

In order to change this period, the ProActive Node must be started with the property *node.dataspace.cache.invalidation.period* (in miliseconds).

The property *node.dataspace.cachedir* can also be used to control the cache location on the node.

== Script Languages

=== Script Engines Names
include::./references/ScriptEngines.adoc[]

include::./references/ScriptLanguageSupport.adoc[]

== Proactive Catalog: Object Storage and Versioning

The *ProActive Catalog* provides the storage and versioning of Workflows and several other objects inside *Buckets*. It also features a searching functionality using a https://graphql.org/[GraphQL] query language to fetch Workflows based on particular parameters.
The Catalog is a RESTful service. A https://swagger.io/[Swagger] +++<a class="catalogRestUrl" href="/catalog" target="_blank">interface</a>+++ is provided to understand and interact with the service.

This chapter will cover:

 * ProActive Catalog *main concepts*.
 * How to interact with the Catalog from the various *ProActive Workflows and Scheduling Portals*.

The link:../admin/ProActiveAdminGuide.html#_catalog[Catalog administration guide] describe how the catalog can be configured and how access control of buckets can be enforced.

=== Bucket concept

A *Bucket* is a collection of _ProActive Objects_ and in particular _ProActive Workflows_ that can be shared between users.

When the ProActive Scheduler is first started, it contains already a predefined set of buckets, such as:

* _controls_ (set of workflows containing basic constructs such as <<_branch,branch>>,<<_loop,loop>> or <<_replicate,replicate>>)
* _basic_examples_ (set of Workflows samples publicly readable)
* _notification_tools_ (set of tasks which can be used to send email or web notifications and/or validations).
* _data_connectors_ (set of Workflows which can be used to transfer files and data from various sources as explained in the <<_data_connectors,Data Connectors chapter>>)


Listing the Catalog for existing Buckets is done using the following HTTP request (protocol, port and hostname needs to be adapted accordingly):

    GET http://localhost:8080/catalog/buckets

It is also possible to list all objects inside a particular Bucket using its `bucketName`:

    GET http://localhost:8080/catalog/buckets/{bucketName}/resources

Then, we can fetch a particular object based on its `name`:

    GET http://localhost:8080/catalog/buckets/{bucketName}/resources/{name}

NOTE: By default, the Catalog will always return the latest version of the objects.

=== Bucket naming requirements

Every bucket is identified by a unique bucket name. The bucket naming should match the following rules:

* The bucket name must be between 3 and 63 characters long and can contain only lower-case characters, numbers, and dashes.

* A bucket name must start with a lowercase letter and cannot terminate with a dash.

=== Object versioning

The Catalog provides versioning of objects. You can list all the revisions of a particular object using the HTTP request:

    GET http://localhost:8080/catalog/buckets/{bucketName}/resources/{name}/revisions

The revision of objects is identified by its `commit_time`. Commit time specifies the time when the object's version was added in the Catalog.
You can fetch an object detailed metadata information using its `name` and `commit_time`:

    GET http://localhost:8080/catalog/buckets/{bucketName}/resources/{name}/revisions/{commit_time}

When an object revision is added to the catalog, depending on its type, it may be parsed by the catalog service to extract some meaningful information.

For example, from a <<_glossary_workflow,*ProActive Workflow*>>, the _workflow name_, _project_name_, _description_, _documentation_, _<<_generic_information>>_ and _<<_workflow_variables>>_ are extracted.

These information are used in the various portals which interacts with the catalog such as the +++<a class="automationDashboardUrl" href="/automation-dashboard/#/portal/workflow-automation" target="_blank">Workflow Automation Portal</a>+++.

=== Retrieving and searching Objects

==== Get an Object from the REST API

From REST API it's possible to retrieve the raw content of a specific revision of an object. For this case it's required to specify `name` and `commit_time` of the object's  revision:

    GET http://localhost:8080/catalog/buckets/{bucketName}/resources/{name}/revisions/{commit_time}/raw

In order to get the raw content of a last revision of an object use next REST API endpoint:

    GET http://localhost:8080/catalog//buckets/{bucketName}/resources/{name}/raw

In this case you need to provide only the `name` of an object.

NOTE: A complete documentation of the Catalog REST API is available on the following +++<a class="catalogRestUrl" href="/catalog" target="_blank">link</a>+++.

==== GraphQL usage

https://graphql.org/[GraphQL] is the standardized query language, which  provides opportunity to search and retrieve the Workflow by specified criterion from the Catalog.
NOTE: Please follow the +++<a class="catalogGraphQLUrl" href="/catalog/graphiql" target="_blank">graphiql endpoint</a>+++ in order to query for the specific Workflow.

=== Catalog Portal
The Catalog Portal provides the capability to store objects like Workflows, Calendars, Scripts, etc.
Powerful versioning together with full access control (RBAC) is supported, and users can easily share Workflows, templates, and other objects between teams, and various environments (Dev, Test, Staging, Prod).

image::catalog-portal-context-menu.png[align=center]

==== Creating new buckets
Create a new bucket easily by clicking on the `plus` button.

image::create-new-bucket.png[align=left]

In the `Create the new bucket` window, it is possible to associate a bucket to a specific users group.

By doing so, only users from the same group will be able to access the content of the bucket.

The content of the buckets associated with the default - `no group`  is accessible by any user, regardless of the groups they belong to.
A bucket with no associated group is also known as a _public bucket_.

More information regarding bucket access control is available in the link:../admin/ProActiveAdminGuide.html#_catalog[Catalog administration guide].

==== Removing Objects Inside a Bucket
Select the objects to remove (CTRL + left click to select multiple objects) and click on the `trash` button.

WARNING: All the object's content will be removed from the database and it cannot be restored.

==== Exporting/Importing Objects into the Catalog
Catalog Objects can be exported to a local archive, and share them easily by email, cloud, etc.  The same archive can be imported again in the Catalog on the same scheduler or in a different one.

TIP: Use this feature to easily share Catalog objects across different environments.

To export the selected objects as a ZIP archive, press the download button from portal view.

image::download-catalog-objects.png[align=left]

To import, either a downloaded catalog archive zip file or a single object, click on the upload button and follow the instructions:

image::upload-catalog-objects.png[align=left]

* *Object Kind*: The kind of object to add. New Kinds can be added by clicking the `plus` button.

* *Content Type*: The Content Type is used to indicate the media type of the resource. New content Types can be added by clicking the `plus` button.

WARNING: In case of uploading an archive, all the objects in the zip must have the same Kind and Content Type.


==== Object Versioning in Catalog Portal
The HEAD of a Catalog object corresponds to the last commit and it is displayed on the portal.

In order to see all the commits of the selected Object, please click on the `clock` button inside the description area.

The commits are shown in chronological order by commit time.

It is possible to restore any previous commit to the HEAD position by clicking the `restore` button.

image::revisions-catalog.png[align=center]

== Third-party credentials

=== Overview

Tasks executed by <<_glossary_proactive_scheduler,*ProActive
Scheduler*>> might need to use a password or another kind of
credentials to acces third-party services or applications. For example
a user might wish to pass his MySQL password to Native Task which runs
a `mysql` command to dump a database.

In such cases it is often desireable to store the credentials
separately from the <<_glossary_workflow,*Workflow*>>
definition. *ProActive Scheduler* provides such facility.

Third-party credentials in *ProActive Scheduler* are user-defined
key-value pairs of strings stored on the server side in encrypted
form. The credentals are accessible in the tasks executed by the user
via API (Script and Java Tasks) or variable substitution (arguments of
Native Tasks and parameters of Java Tasks).

=== Managing third-party credentials

Methods to add or remove the credentials and to list the stored
credential keys are exposed in both Java and REST APIs.

End users can manage their credentials using the
<<_glossary_scheduler_web_interface,Scheduler Web Interface>> (Portal
-> Manage third-party credentials) or the
<<_scheduler_command_line,Command Line Interface>>.

==== Example CLI usage

Add credential:

    $ ./bin/proactive-client --put-credential MY_MYSQL_PASSWORD mypassword
    Credential "MY_MYSQL_PASSWORD" successfully stored.

List credentials (only keys are listed):

    $ ./bin/proactive-client --list-credentials
    [...]
    MY_MYSQL_PASSWORD

Remove credential:

    $ ./bin/proactive-client --remove-credential MY_MYSQL_PASSWORD
    Credential "MY_MYSQL_PASSWORD" successfully removed.

=== Using third-party credentials

==== In a Script Task

In a <<_glossary_task_executable_script, Script Task>>, the `credentials` <<_glossary_script_bindings,script binding>> is a hash map containing all user's
credentials:

[source,groovy]
----
// mysqlPassword will contain the value corresponding to "MY_MYSQL_PASSWORD" key
mysqlPassword = credentials.get('MY_MYSQL_PASSWORD')
----

NOTE: The `credentials` <<_glossary_script_bindings,script binding>> can also be used in <<_glossary_additional_task_scripts,additional scripts>> defined inside a <<_glossary_task,ProActive Task>>.
To know in which scripts `credentials` is available, study the <<_variables_quick_reference,Script Bindings Reference>>.

==== In Java Task

In a <<_glossary_task_executable_java, Java Task>>, the method `getThirdPartyCredential` of `JavaExecutable`
returns the credential corresponding to the key passed as parameter:

[source,java]
----
public class PrintAndReturnCredentialsTask extends JavaExecutable {
  @Override
  public Serializable execute(TaskResult... results) throws Throwable {
    // mysqlPassword will contain the value corresponding to "MY_MYSQL_PASSWORD" key
    String mysqlPassword = getThirdPartyCredential("MY_MYSQL_PASSWORD");
    [...]
  }
}
----

Another way to use credentials in Java tasks is via parameters. If a
parameter contains a string of the form `$credentials_<credential
key>`, the string is replaced with the value of the corresponding
credential:

[source,xml]
----
<task name="...">
  <javaExecutable class="...">
    <parameters>
      <!-- mysqlPassword will contain the value corresponding to "MY_MYSQL_PASSWORD" key -->
      <parameter name="mysqlPassword" value="$credentials_MY_MYSQL_PASSWORD"/>
    </parameters>
  </javaExecutable>
</task>
----

==== In a Native Task

Finally, a credential can be passed to a <<_glossary_task_executable_native,Native Task>> via
argumens. Note that, as with Java Task parameters, the `$credentials_`
prefix is necessary. In the example below, `/bin/echo` will be called
with the value corresponding to the key `MY_MYSQL_PASSWORD` (if the
key is not present, no replacement occurs):

[source,xml]
----
<task name="Task1">
  <nativeExecutable>
    <staticCommand value="/bin/echo" >
      <arguments>
        <argument value="$credentials_MY_MYSQL_PASSWORD"/>
      </arguments>
    </staticCommand>
  </nativeExecutable>
</task>
----

[[_task_apis]]
== Scheduler, Resource Manager, DataSpace, and Synchronization APIs

From a <<_glossary_task_executable_script,Script Task>>, several APIs are accessible via Java objects bound to dedicated <<_glossary_script_bindings,script bindings>>:

- Scheduler API: using the `schedulerapi` binding, it is possible to interact directly with the scheduler server and do several operations (submit jobs, wait for tasks termination, list running jobs, etc.).
- Resource Manager API: using the `rmapi` binding, it is possible to interact directly with the RM and do several operations (lock nodes, change node tags, monitor nodes, get thread dump, etc.).
- DataSpace API: the `userspaceuri` or `globalspaceuri` bindings allow to manipulate files present in User or Global spaces. Operations include listing, uploading, downloading, or deleting files.
- Synchronization API: using the `synchronizationapi` binding, it is possible to handle advanced task synchronization dynamically.


=== Scheduler API

From inside a <<_glossary_task_executable_script,Script Task>>, you can use the Scheduler API binding like the following:

[source,groovy]
----
// importing necessary classes
import org.ow2.proactive.scheduler.common.job.*
import org.ow2.proactive.scheduler.common.task.*
import org.ow2.proactive.scripting.*


// connect to the scheduler
schedulerapi.connect()

// create a hello world job
job = new TaskFlowJob()
job.setName("HelloJob")
task = new ScriptTask()
task.setName("HelloTask")
task.setScript(new TaskScript(new SimpleScript("println 'Hello World'", "groovy")))
job.addTask(task)

// submitting the job
jobid = schedulerapi.submit(job)

// Wait for the task termination
taskResult = schedulerapi.waitForTask(jobid.toString(), "HelloTask", 120000)

// displaying the task output
println taskResult.getOutput().getAllLogs(false)

----

The complete API description can be found in the link:../javadoc/org/ow2/proactive/scheduler/task/client/SchedulerNodeClient.html[SchedulerNodeClient JavaDoc].

NOTE: The `schedulerapi` <<_glossary_script_bindings,script binding>> can also be used in <<_glossary_additional_task_scripts,additional scripts>> defined inside a <<_glossary_task,ProActive Task>>.
To know in which scripts `schedulerapi` is available, study the <<_variables_quick_reference,Script Bindings Reference>>.


=== Resource Manager API

From inside a <<_glossary_task_executable_script,Script Task>>, you can use the Resource Manager API binding like the following:

[source,groovy]
----

// connect to the rm
rmapi.connect()

// displaying the RM state
full = rmapi.getRMStateFull()
full.getNodesEvent().each { event ->
    println(event.getNodeUrl())
    println(event.getNodeState())
}

// add node token to the current node
// get current node url
nodeUrl = variables.get("PA_NODE_URL")
rmapi.addNodeToken(nodeUrl, "MyOwnToken")


println "Test rmapi.getTopology() " + rmapi.getTopology()
println "Test rmapi.getExistingNodeSources() " + rmapi.getExistingNodeSources()
println "Test rmapi.getInfrasToPoliciesMapping() " + rmapi.getInfrasToPoliciesMapping()
println "Test rmapi.getConnectionInfo() " + rmapi.getConnectionInfo()
println "Test rmapi.getRMStateFull() " + rmapi.getRMStateFull()
println "Test rmapi.getRMThreadDump() " + rmapi.getRMThreadDump()
println "Test rmapi.getState() " + rmapi.getState()
println "Test rmapi.getSupportedNodeSourceInfrastructures() " + rmapi.getSupportedNodeSourceInfrastructures()
println "Test rmapi.getSupportedNodeSourcePolicies() " + rmapi.getSupportedNodeSourcePolicies()
println "Test rmapi.getVersion() " + rmapi.getVersion()
println "Test rmapi.isActive() " + rmapi.isActive()


// do not forget to disconnect from the rm
rmapi.disconnect();
----

The complete API description can be found in the link:../rest[Resource Manager Rest Interface].

NOTE: The `rmapi` <<_glossary_script_bindings,script binding>> can also be used in <<_glossary_additional_task_scripts,additional scripts>> defined inside a <<_glossary_task,ProActive Task>>.
To know in which scripts `rmapi` is available, study the <<_variables_quick_reference,Script Bindings Reference>>.



[[_dataspace_apis]]
=== DataSpace API

The traditional way to transfer files from the user or global space to a task is by using file transfer directives as described in chapter <<_data_spaces>>.

Where file transfer directives are sufficient to cover usual cases, it is sometimes necessary to manipulate directly the dataspace API to have a finer control level.

Below is an example use of this api inside a <<_glossary_task_executable_script,Script Task>>:

[source,groovy]
----
// connect to the user space
userspaceapi.connect()

// push file
inFile = new File("inFile.txt");
inFile.write("HelloWorld")
userspaceapi.pushFile(inFile, "remoteDir/inFile.txt")

// list files

remotefiles = userspaceapi.listFiles("remoteDir", "*.txt"
println remotefiles

// pull File
outFile = new File("outFile.txt")
userspaceapi.pullFile("remote/inFile.txt", outFile)

println outFile.text

----

The complete description of user and global space APIs can be found in the link:../javadoc/org/ow2/proactive/scheduler/task/client/DataSpaceNodeClient.html[DataSpaceNodeClient JavaDoc].

NOTE: The `userspaceapi` and `globalspaceapi` <<_glossary_script_bindings,script bindings>> can also be used in <<_glossary_additional_task_scripts,additional scripts>> defined inside a <<_glossary_task,ProActive Task>>.
To know in which scripts these bindings are available, study the <<_variables_quick_reference,Script Bindings Reference>>.

[[_task_synchronization_api]]
=== Synchronization API

This Synchronization API allows for both communication and synchronization between Tasks and between Jobs dynamically at execution. It is based on a Key-Value Store offering atomic operations. It enables to easily put into action all classical synchronization patterns: Critical Sections and Mutual Exclusion, Rendez-vous, Barriers, Producer/Consumer...

Task synchronization is traditionally handled by the ProActive Scheduler through <<Dependency, Task Dependencies>>, where dependent ProActive Tasks are started only after their parents Tasks completed.

In some cases, *static task dependencies* are not enough to synchronize tasks execution.

This is the case when a task depends on the state of another task executed in a different branch of a workflow, a sibling task or even another job/workflow.

For example, let's suppose workflow _A_ contains a single task _A_1_ starting an apache server. Task _A_1_ starts the server and remains alive while the server is up.
When workflow _A_ is killed, task _A_1_ stops the Apache server.

A task _B_1_ of another workflow _B_ wants to interact with this server.

*Problem:* task _B_1_ does not know if the apache server is up and how to contact it.

Using *Task Synchonization API*, task _A_1_ can advertise the server URL to the Synchronization Service.

Task _B_1_ can use Task Synchonization API to wait until the apache server is advertised, it can also perform the necessary operations and advertise task _A_1_ that the operation is complete and the apache server can be terminated.

As we can see, Task Synchronization API can be used for two-ways synchronization.

Synchronizations can be used in any part of a Task (Pre/Post/Clean Scripts, Task Implementation, Selection Script). Using Synchronization API within Selection Scripts is a way to avoid a Task to be started (consuming a Node) and to be actually doing nothing, just waiting for a specific condition to occur.

==== Usage

*Task Synchronization API* is a *Java API* defined by the following link:../javadoc/org/ow2/proactive/scheduler/synchronization/Synchronization.html[API documentation].

The Synchronization API is connected to a centralized *Synchronization Service*. This service ensures that each request is executed atomically, and that changes are persisted on disk.

The Synchronization API is available inside ProActive Tasks through the `synchronizationapi` <<_glossary_script_bindings,script binding>>.


===== Channels

The *Synchronization Service* works as a _Key-Value Store_ organized in *channels*. Each *channel* acts as a private _Key-Value Store_.

This means that each _put_ operation is identified by a 3-tuple: _<Channel_identifier, Key_binding, Value>_.

Users of the Synchronization API are responsible to create *channels* as fit their needs. Channels have no notion of *ownership*, a channel created by workflow A started by user _Alice_ can be used by workflow B started by user _Bob_.

This is because Synchronization API is often used to synchronize workflow tasks across multiple users.

Therefore, *channel naming* is important and should be precise enough to avoid accidental overlap. Channels should be created when needed and deleted after use.

For example, a channel which is used only inside a specific job instance (to synchronize tasks withing this job) should be created inside some *initialization task* at the beginning of this job, and deleted in some *cleaning task* at the end. The channel name should contain the <<_glossary_job_id, Job Id>>.

When channels are created, the user can decide if the channel should be persisted on disk or kept in memory only.

On startup, the Synchronization Service contains only the persistent channels which were previously created using the Synchronization API. In-memory channels created before the reboot of the scheduler are lost.

===== API Description

The Synchronization API is similar to the https://docs.oracle.com/javase/8/docs/api/java/util/Map.html[Java 8 Map interface], with the following differences:

 * It contains methods to create/delete _channels_ and methods to interact with the _channel Map_ itself.

 * Each channel Map operations must take a _channel identifier_ parameter.

 * The Synchronization API supports https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html[Java 8 lambdas], but lambdas must be passed as string arguments defining http://groovy-lang.org/closures.html[Groovy Closures]. For example, `+compute("channel1", "key1", "{k, x -> x+1}")+` instead of `+compute("channel1", "key1", (k, x) -> x+1)+`.

 * The Synchronization Service guaranties that multiple operations, coming from different ProActive Tasks, will all be executed *atomically*.

 * In addition to the methods present in the https://docs.oracle.com/javase/8/docs/api/java/util/Map.html[Java 8 Map interface], Synchronization API provides *blocking methods* to wait for a specific _condition_ on a channel.
 This is mainly why this API is called *Synchronization*, it allows for different ProActive Tasks to be blocked until specific conditions are met.

 * When an error occurs during the Groovy Closure compilation or execution, dedicated exceptions (link:../javadoc/org/ow2/proactive/scheduler/synchronization/CompilationException.html[CompilationException] or link:../javadoc/org/ow2/proactive/scheduler/synchronization/ClosureEvaluationException.html[ClosureEvaluationException]) will be thrown.


==== Examples

===== Example 1: Simple Key/Value With Selection Script

In this first example, we will show how one task can delay the execution of another task using the Synchronization API and a <<_selection,selection script>>.

image::KeyValue.png[Key/Value With Selection Script, , title="Key/Value With Selection Script"]

This workflow contains the following Tasks:

 * *Init*: Initialize the channel. This task creates a channel using the current _job id_. It also sets a `lock` binding in the key/value store with an initial _true_ value.
+
[source, groovy]
----
jobid = variables.get("PA_JOB_ID")
synchronizationapi.createChannel(jobid, false)
synchronizationapi.put(jobid, "lock", true)
println "Channel " + jobid + " created."
----

 * *TaskB_Wait*: Wait to be unlocked. This task will not be executed until the `lock` binding changed to _false_. A <<_selection, selection script>> allows to handle this verification:
+
[source, groovy]
----
selected = !(synchronizationapi.get(variables.get("PA_JOB_ID"), "lock"))
----

 * *TaskA*: Unlock TaskB. This task will sleep for a few seconds and then unlock TaskB using the Synchronization API:
+
[source, groovy]
----
println "Sleeping 5 seconds"
Thread.sleep(5000)
println "Unlocking Task B"
synchronizationapi.put(variables.get("PA_JOB_ID"), "lock", false)
----

 * *Clean*: Delete the channel. This task simply deletes the channel used in this job. As there is no automatic mechanism to remove channels, it is necessary to delete them explicitely when they are not used any more.
+
[source, groovy]
----
jobid = variables.get("PA_JOB_ID")
synchronizationapi.deleteChannel(jobid )
println "Channel " + jobid + " deleted."
----

Here is output of the Key/Value workflow:
----
[28t2@trydev.activeeon.com;14:24:22] Channel 28 created.
[28t0@trydev.activeeon.com;14:24:28] Sleeping 5 seconds
[28t0@trydev.activeeon.com;14:24:33] Unlocking Task B
[28t1@trydev.activeeon.com;14:24:40] Task B has been unlocked by Task A
[28t3@trydev.activeeon.com;14:24:46] Channel 28 deleted.
----

NOTE: It is also possible to debug the operations performed on the Synchronization Store. This is possible by using the *Server Logs* associated with the job. Server Logs are very verbose, the _[Synchronization]_ pattern helps to find logs associated with the Synchronization API:
----
[2018-04-24 14:24:22,685 de72716883 INFO            o.o.p.s.u.TaskLogger] task 28t2 (Init) [Synchronization]Created new memory channel '28'
[2018-04-24 14:24:22,786 de72716883 INFO            o.o.p.s.u.TaskLogger] task 28t2 (Init) [Synchronization][Channel=28] Put true on key 'lock', previous value was null
[2018-04-24 14:24:34,431 de72716883 INFO            o.o.p.s.u.TaskLogger] task 28t0 (TaskA) [Synchronization][Channel=28] Put false on key 'lock', previous value was true
[2018-04-24 14:24:46,882 de72716883 INFO            o.o.p.s.u.TaskLogger] task 28t3 (Clean) [Synchronization]Deleted memory channel '28'
----

The Complete Workflow example can be downloaded link:examples/KeyValue.xml[here].

===== Example 2: Simple Key/Value with Explicit Wait

In this second example, we will show how one task can delay the execution of another task using the Synchronization API and an explicit wait call.

This example is very similar to the first example, but instead of delaying the execution of TaskB using a selection script, TaskB will start its execution and explicitly call the Synchronization API to wait.

 * Tasks *Init*, *TaskA* and *Clean* do not change

 * *TaskB_Wait* is modified. The selection script is removed and instead the following code is used in the main task definition:
+
[source, groovy]
----
println "Waiting for Task A"
synchronizationapi.waitUntil(variables.get("PA_JOB_ID"), "lock", "{k, x -> x == false}")
println "Task B has been unlocked by Task A"
----
+
As you can see, the link:../javadoc/org/ow2/proactive/scheduler/synchronization/Synchronization.html#waitUntil-java.lang.String-java.lang.String-java.lang.String-[waitUntil] method expects a https://docs.oracle.com/javase/8/docs/api/java/util/function/BiPredicate.html?is-external=true[BiPredicate] defined as a string http://groovy-lang.org/closures.html[Groovy Closure].
The predicate receives two parameters: `k` contains the key, and `x` contains the binding associated with this key.
This predicate is evaluated on the *lock* binding, and waits until this binding *== false*.

Here is the output of the Example 2 workflow:
----
[29t2@trydev.activeeon.com;14:43:42] Channel 29 created.
[29t0@trydev.activeeon.com;14:43:49] Sleeping 5 seconds
[29t1@trydev.activeeon.com;14:43:48] Waiting for Task A
[29t0@trydev.activeeon.com;14:43:54] Unlocking Task B
[29t1@trydev.activeeon.com;14:43:55] Task B has been unlocked by Task A
[29t3@trydev.activeeon.com;14:44:01] Channel 29 deleted.
----

The Complete Workflow example can be downloaded link:examples/KeyValueWait.xml[here].

===== Example 3: Critical Section

In this last example, we will show how we can create a *critical section* inside a workflow, which means, a section of the workflow which can only be accessed by a configurable number of *slots*.

The _Critical Section_ workflow is defined with a <<_replicate, Replicate Control Structure>>:

image::CriticalSection.png[Critical Section, , title="Critical Section"]

It contains the following Tasks:

 * *Init*: Initialize the channel. This task creates a channel using the current _job id_. It also sets a `available_slots` binding in the key/value store with an initial value based on the workflow user-defined `NB_SLOTS` <<_job_variables, job variable>>.
+
[source, groovy]
----
jobid = variables.get("PA_JOB_ID")
synchronizationapi.createChannel(jobid, false)
synchronizationapi.put(jobid, "available_slots", Integer.parseInt(variables.get("NB_SLOTS")))
println "Channel " + jobid + " created."
----
+
This tasks also define a <<_control_flow_scripts, control flow script>> used to define the number of replicated tasks. The number of replicated tasks is parametrized with the user-defined `NB_TASKS` <<_job_variables, job variable>>:
+
[source, groovy]
----
runs=Integer.parseInt(variables.get("NB_TASKS"))
----

 * *Section*: Wait for the critical section to be available. This task will block until the number of available slots is greater than 0. As soon as at least one slot is available, it decrements the `available_slots` counter and perform some computation.
When the computation is terminated, it releases the slot by incrementing back the `available_slots` counter.
+
[source, groovy]
----
println "Waiting for available slot"
jobid = variables.get("PA_JOB_ID")
synchronizationapi.waitUntilThen(jobid, "available_slots", "{k, x -> x > 0}", "{k, x -> x - 1}")
println "Enter critical section"
// simulate some computation
Thread.sleep(10000)
println "Release slot"
synchronizationapi.compute(jobid,"available_slots", "{k, x -> x + 1}")
----
+
As you can see, the first method used in this section is link:../javadoc/org/ow2/proactive/scheduler/synchronization/Synchronization.html#waitUntilThen-java.lang.String-java.lang.String-java.lang.String-java.lang.String-[waitUntilThen]. This method expects both a https://docs.oracle.com/javase/8/docs/api/java/util/function/BiPredicate.html?is-external=true[BiPredicate] and a https://docs.oracle.com/javase/8/docs/api/java/util/function/BiFunction.html?is-external=true[BiFunction] defined as strings http://groovy-lang.org/closures.html[Groovy Closure].
+
The semantic of this method is to wait until the predicate is met and, as soon as it is, immediately perform a remapping.
+
In our scenario, the number of available slots is immediately decremented to reserve a slot and enter the critical section.
+
Releasing of the slot is performed at the end of the task using the link:../javadoc/org/ow2/proactive/scheduler/synchronization/Synchronization.html#compute-java.lang.String-java.lang.String-java.lang.String-[compute] method.

 * *Clean*: Delete the channel. Same code as the previous examples.

Here is the output of the Example 3 workflow:
----
[3t0@trydev.activeeon.com;16:14:14] Channel 3 created.
[3t1@trydev.activeeon.com;16:14:22] Waiting for available slot
[3t4@trydev.activeeon.com;16:14:22] Waiting for available slot
[3t3@trydev.activeeon.com;16:14:22] Waiting for available slot
[3t5@trydev.activeeon.com;16:14:22] Waiting for available slot
[3t1@trydev.activeeon.com;16:14:23] Enter critical section
[3t4@trydev.activeeon.com;16:14:23] Enter critical section
[3t4@trydev.activeeon.com;16:14:33] Release slot
[3t1@trydev.activeeon.com;16:14:33] Release slot
[3t3@trydev.activeeon.com;16:14:33] Enter critical section
[3t5@trydev.activeeon.com;16:14:34] Enter critical section
[3t6@trydev.activeeon.com;16:14:38] Waiting for available slot
[3t3@trydev.activeeon.com;16:14:43] Release slot
[3t5@trydev.activeeon.com;16:14:44] Release slot
[3t6@trydev.activeeon.com;16:14:44] Enter critical section
[3t6@trydev.activeeon.com;16:14:54] Release slot
[3t2@trydev.activeeon.com;16:14:59] Channel 3 deleted.
----

We can see that no more than two replicated tasks enter the critical section at the same time, and that releasing slots allows new tasks to enter the critical section.

The Complete Workflow example can be downloaded link:examples/CriticalSection.xml[here].

CAUTION: Implementing the Critical Section example using <<_selection,selection scripts>> rather than explicit wait methods is more *complex*.
The reason behind is that selection scripts are meant to be *stateless*.
The same selection script is executed on all ProActive Nodes by the Scheduler before deciding if a Node can be used to execute a single Task.
In our use case, we must both decide *atomically* if a slot is available (_stateless_) and reserve a slot (_stateful_). This decision will be performed *simultaneously* on all available ProActive Nodes.
An example implementation can be downloaded link:examples/CriticalSectionWithSelectionScripts.xml[here]. It makes use of a `reserved_slots` binding containing a set of `task ids`.

==== Conclusion

Task Synchronization API can be used for multiple dynamic synchronization patterns such as:

 * *Cross-workflow* synchronization

 * *Critical Sections*

 * *Barriers* (Wait for several parallel tasks to reach a certain point)

 * *Producer / Consumer*

A complete example of Producer / Consumer, _ServiceDeployerConsumer_ can be downloaded link:examples/ServiceDeployerConsumer.xml[here].

== Scheduling policies

See link:../admin/ProActiveAdminGuide.html#_scheduling_policies[Admin Guide] to configure scheduling policies.

=== Earliest deadline first (EDF) policy

Scheduler has `Earliest deadline first policy` (EDF policy) that prioritizes jobs with deadlines.
Overall, the general principal is the following: a job that needs to be started as soon as possible to meet its deadline
taking into account its execution time has higher priority.

The EDF policy considers two Generic Information items: `JOB_DDL` and `JOB_EXEC_TIME`.

`JOB_DDL` represents job deadline. Job deadline can be set in one of the following format:

1. absolute format: `YYYY-MM-dd`T`HH:mm:ss+ZZ`, e.g. `2018-08-14T08:40:30+02:00`

2. relative (to the submission time) format: `+HH:mm:ss` , e.g. `+5:30:00`, or `+mm:ss`, e.g. `+4:30`, or `+ss`, e.g. `+45` (45 seconds)

If job deadline is absolute then its value equals to `JOB_DDL`.

If job deadline is relative then its value equals to `submission time` + `JOB_DDL`.

`JOB_EXEC_TIME` represents job expected execution time in the following format: `HH:mm:ss` , e.g. `12:30:00`, `5:30:00`,
or `mm:ss`, e.g. `4:30`, or `ss`, e.g. `45` (45 seconds).

EDF policy orders jobs by applying the rules below.
The rule considers jobs at submission time when they are still pending, and orders them by priority.


Thus EDF policy applies these rules (in the given order) until one rule actually applies.
Here is the ordered list of rules for the EDF policy:

1. compare job's intrinsic priority (HIGHEST, HIGH, NORMAL, LOW, LOWEST)

2. job with deadline has priority over job without deadline

3. job that is already started has priority over job that has not yet started

4. job that started earlier has priority over job that was started later

5. job with the earliest `JOB_DDL` minus `JOB_EXEC_TIME` has a priority

6. job with earliest submission time.

==== Email notifications

EDF policy sends 3 types of email notifications:

1. (Arriving soon) When job deadline is at risk (if the job is not started in the next X minutes, its deadline will be missed)

2. When job will likely miss its deadline (i.e if the provided `JOB_EXEC_TIME` exceeds the left time until the deadline)

3. (Arriving soon) When job has already missed its deadline.

Policy sends emails to the address specified in `EMAIL` Generic Information of the job.

To enable email notifications see link:../admin/ProActiveAdminGuide.html#_get_notifications[Admin Guide].


== Data Connectors

include::./references/DataConnectors.adoc[]


== Addons

include::./references/StatisticsOnProActiveJobsAndResourceUsageReference.adoc[]

include::./references/LDAPQueryTasks.adoc[]

=== PHP Task

The PHP task is a special, predefined task which executes a PHP script on a ProActive Node’s local PHP installation.
The PHP script to execute will be downloaded from the ProActive server <<_global_and_user_spaces, global space>>. So, the PHP script must be present in the dataspace beforehand. The task can also be modified to download the PHP script from other sources. Log forwarding and log streaming during PHP execution is conveniently available through the Scheduler portal.

==== Node configuration
For a ProActive Node to execute a PHP script, PHP must be installed on the machine of the ProActive Node. The PHP task has a <<_selection,selection script>> which validates a correct PHP installation by searching the PATH and validating if the PHP can be executed successfully.
The static selection script validates the PHP execution once and stores the result in the cache, so removing or installing PHP requires a restart of the node or a switch to the dynamic selection script.
The selection script predefined in the PHP task does not validate the PHP version, therefore it is advised to use the same PHP version on the ProActive Nodes or to improve the selection script itself.


== Reference

=== Job and task specification

Workflows are written in XML and we provide a XSD grammar to help you write and validate them.
The Workflows XSD is available link:https://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.3/schedulerjob.xsd[here, window="_blank"]
and you can also find the documentation link:schedulerjob.html[here, window="_blank"].

TIP: Setup your IDE to use the https://www.activeeon.com/public_content/schemas/proactive/jobdescriptor/3.3/schedulerjob.xsd[Workflow XSD^],
you will benefit from live validation and completion!

=== Studio Tasks
include::./references/Tasks.adoc[]

[[_variables_quick_reference]]
=== Script Bindings Reference
include::./references/VariablesReference.adoc[]

=== Topology Types
include::./references/TopologyTypes.adoc[]

[[_scheduler_command_line]]
=== Command Line
include::../CLI.adoc[]
include::../common-footer.adoc[]
